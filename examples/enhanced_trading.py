"""
BTC-USDT-SWAP å¢å¼ºç‰ˆçŸ­çº¿äº¤æ˜“ï¼ˆæ–¹æ¡ˆAï¼šåŸå§‹æ•°æ®+æŠ€æœ¯æŒ‡æ ‡æ··åˆï¼‰
æä¾›åŸå§‹Kçº¿ã€è®¢å•ç°¿æ•°æ®ç»™AIï¼Œå……åˆ†å‘æŒ¥AIçš„åˆ†æèƒ½åŠ›
åŒæ—¶ä¿ç•™æŠ€æœ¯æŒ‡æ ‡ä½œä¸ºè¾…åŠ©å‚è€ƒ
"""
import sys
import os,re

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

import argparse
import time
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor

import requests
import json
from datetime import datetime, timedelta
from loguru import logger

from src.config.settings import config
from src.core.rest_client import OKXRestClient
from src.api.trade import TradeAPI
from src.api.position import PositionAPI
from src.api.market import MarketAPI
from src.api.public import PublicAPI
from src.api.account import AccountAPI
from src.ai.data_manager import DataManager
from src.ai.feature_engineer import FeatureEngineer
from src.execution.smart_executor import SmartOrderExecutor
from src.utils.fee_calculator import FeeCalculator
class BTCEnhancedBotRaw:
    """BTC-USDT-SWAP å¢å¼ºç‰ˆäº¤æ˜“æœºå™¨äººï¼ˆæ–¹æ¡ˆAï¼šåŸå§‹æ•°æ®ï¼‰"""

    def __init__(self, auto_execute: bool = False):
        """
        åˆå§‹åŒ–å¢å¼ºç‰ˆäº¤æ˜“æœºå™¨äººï¼ˆåŸå§‹æ•°æ®ç‰ˆæœ¬ï¼‰

        Args:
            auto_execute: æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œäº¤æ˜“
            use_realtime: æ˜¯å¦å¯ç”¨å®æ—¶æ•°æ®é‡‡é›†
        """
        self.inst_id = config.INST_ID  # ä»é…ç½®æ–‡ä»¶è¯»å–äº¤æ˜“æ ‡çš„
        self.auto_execute = auto_execute
        self.executor_=ThreadPoolExecutor()

        # ä»é…ç½®æ–‡ä»¶è¯»å–äº¤æ˜“å‚æ•°
        self.leverage = config.DEFAULT_LEVERAGE  # ä».envè¯»å–æ æ†

        # æ•°æ®æ–°é²œåº¦é˜ˆå€¼ï¼ˆç§’ï¼‰
        self.data_freshness_threshold = 300  # 5åˆ†é’Ÿï¼Œæ•°æ®è¶…è¿‡æ­¤æ—¶é—´è§†ä¸ºæ»å

        # ç”Ÿæˆä¼šè¯ID
        import uuid
        self.session_id = str(uuid.uuid4())[:8]

        # å†…å­˜ç¼“å­˜ï¼šå†å²AIå†³ç­–ï¼ˆåªä¿ç•™æœ€è¿‘10ä¸ªAI response + æ—¶é—´æˆ³ï¼‰
        # å†³ç­–å†å²æ–‡ä»¶è·¯å¾„
        self.ai_decision_history_file = os.path.join(project_root, 'data', 'ai_decision_history.json')
        self.ai_decision_history = []  # [{"content": ai_response_str, "timestamp": "2025-10-27 16:30:45"}, ...]
        self.current_conversation_id = None  # å½“å‰ä¼šè¯çš„æ•°æ®åº“ID

        # ä»æ–‡ä»¶åŠ è½½å†å²å†³ç­–
        self._load_decision_history()
        logger.info(f"âœ“ å·²åŠ è½½ {len(self.ai_decision_history)} æ¡å†å²AIå†³ç­–")

        # è´¦æˆ·ä½™é¢ç¼“å­˜ï¼ˆæé«˜äº¤æ˜“æ‰§è¡Œæ•ˆç‡ï¼‰
        self.cached_balance = 0.0  # ç¼“å­˜çš„USDTä½™é¢
        self.balance_last_update = None  # ä½™é¢æœ€åæ›´æ–°æ—¶é—´
        self.balance_update_thread = None  # ä½™é¢æ›´æ–°çº¿ç¨‹
        self.stop_balance_thread = False  # åœæ­¢ä½™é¢æ›´æ–°çº¿ç¨‹çš„æ ‡å¿—

        # ä»“ä½ç¼“å­˜ï¼ˆæé«˜äº¤æ˜“æ‰§è¡Œæ•ˆç‡ï¼‰
        self.cached_positions = []  # ç¼“å­˜çš„æŒä»“åˆ—è¡¨
        self.positions_last_update = None  # æœ€åæ›´æ–°æ—¶é—´
        self.position_update_thread = None  # åå°æ›´æ–°çº¿ç¨‹
        self.stop_position_thread = False  # åœæ­¢æ ‡å¿—

        # æ­¢ç›ˆæ­¢æŸè®¢å•ç¼“å­˜
        self.cached_stop_orders = {}  # {pos_side: {'stop_loss': {...}, 'take_profit': {...}}}
        self.stop_orders_last_update = None
        self.stop_order_update_thread = None
        self.stop_stop_order_thread = False

        # åˆçº¦ä¿¡æ¯ç¼“å­˜
        self.instrument_info = None

        # å†å²ä»“ä½ç¼“å­˜ï¼ˆä¾›AIåˆ†æä½¿ç”¨ï¼‰
        self.cached_historical_positions = []  # æœ€è¿‘10ç¬”å·²å¹³ä»“ä½
        self.cached_performance_stats = {}  # 30å¤©æ”¶ç›Šç»Ÿè®¡
        self.history_last_update = None
        self.position_history_thread = None
        self.stop_history_thread = False

        # èµ„é‡‘è´¹ç‡ç¼“å­˜ï¼ˆä¾›AIåˆ†æä½¿ç”¨ï¼‰
        self.cached_funding_rate = None  # æœ€æ–°èµ„é‡‘è´¹ç‡æ•°æ®
        self.funding_rate_last_update = None
        self.funding_rate_update_thread = None
        self.stop_funding_rate_thread = False

        # å¸‚åœºæ•°æ®ç¼“å­˜ï¼ˆæŒä»“é‡ã€äº¤æ˜“é‡ã€ä¸»åŠ¨ä¹°å–ï¼‰
        self.cached_taker_volume = None  # ä¸»åŠ¨ä¹°å–æ•°æ®
        self.cached_open_interest = None  # æŒä»“é‡å’Œäº¤æ˜“é‡æ•°æ®
        self.market_data_last_update = None
        self.market_data_update_thread = None
        self.stop_market_data_thread = False

        # æœºå™¨äººå¯åŠ¨æ—¶é—´ï¼ˆç”¨äºAIç†è§£é•¿æœŸè¿è¡Œä»»åŠ¡ï¼‰
        if config.BOT_START_TIME:
            try:
                # å°è¯•è§£æ.envä¸­é…ç½®çš„å¯åŠ¨æ—¶é—´
                self.bot_start_time = datetime.strptime(config.BOT_START_TIME, '%Y-%m-%d %H:%M:%S')
                logger.info(f"âœ“ ä»é…ç½®åŠ è½½æœºå™¨äººå¯åŠ¨æ—¶é—´: {self.bot_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
            except ValueError as e:
                # è§£æå¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                logger.warning(f"âš ï¸ å¯åŠ¨æ—¶é—´æ ¼å¼é”™è¯¯: {config.BOT_START_TIME}ï¼Œä½¿ç”¨å½“å‰æ—¶é—´")
                self.bot_start_time = datetime.now()
        else:
            # æœªé…ç½®å¯åŠ¨æ—¶é—´ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
            self.bot_start_time = datetime.now()
            logger.info(f"âœ“ æœºå™¨äººå¯åŠ¨æ—¶é—´ï¼ˆæœªé…ç½®ï¼Œä½¿ç”¨å½“å‰ï¼‰: {self.bot_start_time.strftime('%Y-%m-%d %H:%M:%S')}")

        # åˆå§‹åŒ–API
        if not config.is_configured():
            raise ValueError("è¯·å…ˆåœ¨.envæ–‡ä»¶ä¸­é…ç½®APIå¯†é’¥")

        self.client = OKXRestClient(
            api_key=config.API_KEY,
            secret_key=config.SECRET_KEY,
            passphrase=config.PASSPHRASE,
            is_demo=config.IS_DEMO,
            use_proxy=config.PROXY_ENABLED,
            proxy=f'http://{config.PROXY_USERNAME}:{config.PROXY_PASSWORD}@{config.PROXY_HOST}:{config.PROXY_PORT}' if config.PROXY_USERNAME else f'http://{config.PROXY_HOST}:{config.PROXY_PORT}' 
        )

        self.trade_api = TradeAPI(self.client)
        self.position_api = PositionAPI(self.client)
        self.market_api = MarketAPI(self.client)
        self.account_api = AccountAPI(self.client)
        self.public_api= PublicAPI(self.client)

        # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        self.data_manager = DataManager()

        # åˆå§‹åŒ–ç‰¹å¾å·¥ç¨‹å¸ˆ
        self.feature_engineer = FeatureEngineer(self.data_manager)

        # åˆå§‹åŒ–æ‰‹ç»­è´¹è®¡ç®—å™¨
        self.fee_calculator = FeeCalculator()

        # åˆå§‹åŒ–æ™ºèƒ½è®¢å•æ‰§è¡Œå™¨ï¼ˆä¼ å…¥data_managerç”¨äºRedisè®¿é—®ï¼‰
        self.executor = SmartOrderExecutor(
            self.trade_api,
            self.position_api,
            self.market_api,
            self.fee_calculator,
            self.public_api,
            self.data_manager
        )

        # è®¾ç½®æ æ†ï¼ˆåªåœ¨å¯åŠ¨æ—¶è®¾ç½®ä¸€æ¬¡ï¼‰
        logger.info(f"âš™ï¸ è®¾ç½®æ æ† {self.leverage}x...")
        try:
            # ä¸ºå¤šç©ºåŒå‘è®¾ç½®æ æ†
            for pos_side in ['long', 'short']:
                lever_result = self.position_api.set_leverage(
                    inst_id=self.inst_id,
                    lever=str(self.leverage),
                    mgn_mode='cross',
                    pos_side=pos_side
                )
                if lever_result['code'] == '0':
                    logger.success(f"âœ“ æ æ†è®¾ç½®æˆåŠŸ: {pos_side} {self.leverage}x")
                else:
                    logger.warning(f"âš ï¸ æ æ†è®¾ç½®å¤±è´¥ï¼ˆå¯èƒ½å·²è®¾ç½®ï¼‰: {pos_side} - {lever_result.get('msg')}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ æ†è®¾ç½®å¼‚å¸¸: {e}")

        # åˆå§‹åŒ–å®æ—¶æ•°æ®é‡‡é›†å™¨ï¼ˆå¯é€‰ï¼‰
        self.realtime_collector = None
        self.collector_task = None


        # è±†åŒ…AIï¼ˆå¦‚æœé…ç½®ï¼‰
        self.doubao_client = None
        self.deepseek_client = None
        self.qwen_client = None
        self.ai_client = None  # ç»Ÿä¸€AIå®¢æˆ·ç«¯æ¥å£

        # æ ¹æ®é…ç½®é€‰æ‹©AIæä¾›å•†
        if config.AI_PROVIDER == 'doubao' and config.DOUBAO_API_KEY:
            try:
                from src.ai.doubao_client import DoubaoClient
                self.doubao_client = DoubaoClient(
                    api_key=config.DOUBAO_API_KEY,
                    endpoint_id=config.DOUBAO_ENDPOINT_ID,
                    model=config.DOUBAO_MODEL,
                    default_timeout=config.DOUBAO_TIMEOUT
                )
                self.ai_client = self.doubao_client
                logger.info(f"âœ“ è±†åŒ…AIå·²å¯ç”¨ (æ¨¡å‹: {config.DOUBAO_MODEL}, è¶…æ—¶: {config.DOUBAO_TIMEOUT}ç§’)")
            except Exception as e:
                logger.warning(f"è±†åŒ…AIåˆå§‹åŒ–å¤±è´¥: {e}")

        elif config.AI_PROVIDER == 'deepseek' and config.DEEPSEEK_API_KEY:
            try:
                from src.ai.deepseek_client import DeepSeekClient
                self.deepseek_client = DeepSeekClient(
                    api_key=config.DEEPSEEK_API_KEY,
                    model=config.DEEPSEEK_MODEL,
                    default_timeout=config.DEEPSEEK_TIMEOUT
                )
                self.ai_client = self.deepseek_client
                logger.info(f"âœ“ DeepSeek AIå·²å¯ç”¨ (æ¨¡å‹: {config.DEEPSEEK_MODEL}, è¶…æ—¶: {config.DEEPSEEK_TIMEOUT}ç§’)")
            except Exception as e:
                logger.warning(f"DeepSeek AIåˆå§‹åŒ–å¤±è´¥: {e}")

        elif config.AI_PROVIDER == 'qwen' and config.QWEN_API_KEY:
            try:
                from src.ai.qwen_client import QwenClient
                self.qwen_client = QwenClient(
                    api_key=config.QWEN_API_KEY,
                    model=config.QWEN_MODEL,
                    default_timeout=config.QWEN_TIMEOUT
                )
                self.ai_client = self.qwen_client
                logger.info(f"âœ“ é€šä¹‰åƒé—®AIå·²å¯ç”¨ (æ¨¡å‹: {config.QWEN_MODEL}, è¶…æ—¶: {config.QWEN_TIMEOUT}ç§’)")
            except Exception as e:
                logger.warning(f"é€šä¹‰åƒé—®AIåˆå§‹åŒ–å¤±è´¥: {e}")

        else:
            logger.warning(f"âš ï¸ æœªé…ç½®AIæˆ–é…ç½®æ— æ•ˆ (AI_PROVIDER={config.AI_PROVIDER})")

        # è·å–å¹¶ç¼“å­˜åˆçº¦ä¿¡æ¯
        try:
            from src.utils.instrument_cache import InstrumentCache
            instrument_cache = InstrumentCache()
            cache_result = instrument_cache.get_instrument_info(
                inst_id=self.inst_id,
                inst_type='SWAP',
                market_api=self.public_api
            )
            if cache_result['success']:
                self.instrument_info = cache_result['data']
                logger.info(f"âœ“ åˆçº¦ä¿¡æ¯å·²ç¼“å­˜: ctVal={self.instrument_info.get('ctVal')}, minSz={self.instrument_info.get('minSz')}")
            else:
                logger.warning(f"âš ï¸ è·å–åˆçº¦ä¿¡æ¯å¤±è´¥: {cache_result.get('error')}")
        except Exception as e:
            logger.warning(f"âš ï¸ åˆçº¦ä¿¡æ¯ç¼“å­˜å¤±è´¥: {e}")

        # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
        logger.info(f"âœ“ å¢å¼ºç‰ˆäº¤æ˜“æœºå™¨äººåˆå§‹åŒ–å®Œæˆï¼ˆæ–¹æ¡ˆAï¼šåŸå§‹æ•°æ®ï¼‰")
        logger.info(f"  è‡ªåŠ¨æ‰§è¡Œ: {auto_execute}")
        logger.info(f"  æ æ†å€æ•°: {self.leverage}x")
        logger.info(f"  æ•°æ®æ–°é²œåº¦é˜ˆå€¼: {self.data_freshness_threshold}ç§’")

        # é£ä¹¦é€šçŸ¥é…ç½®
        self.feishu_enabled = config.FEISHU_ENABLED
        self.feishu_webhook_url = config.FEISHU_WEBHOOK_URL if config.FEISHU_ENABLED else None
        if self.feishu_enabled and self.feishu_webhook_url:
            logger.info(f"  é£ä¹¦é€šçŸ¥: å·²å¯ç”¨")
        else:
            logger.info(f"  é£ä¹¦é€šçŸ¥: æœªå¯ç”¨")
    def send_feishu_content(self,posId):
        """
        å‘é€é£ä¹¦é€šçŸ¥ï¼ˆä»“ä½ä¿¡æ¯ï¼‰- åå°çº¿ç¨‹å¼‚æ­¥æ‰§è¡Œ

        Args:
            position: ä»“ä½ä¿¡æ¯
        """
        # æ£€æŸ¥é£ä¹¦é€šçŸ¥æ˜¯å¦å¯ç”¨
        if not self.feishu_enabled or not self.feishu_webhook_url:
            return
        try:
            position=None
            while not position:
                for posData in self.cached_historical_positions:
                    if str(posData['open_time']) == str(posId):
                        position=posData
                        break
            signal_text=f'{"å¤šä»“" if position["pos_side"] =="long" else "ç©ºä»“"} å·²å¹³ä»“ã€{int(position["leverage"])}xã€‘'
            content_parts = [f"ã€{signal_text}ã€‘" ]
            content_parts.append(f"â–¸ äº¤æ˜“å¯¹: {position['inst_id']}")
            if position.get('avg_px'):
                content_parts.append(f"â–¸ å¼€ä»“ä»·æ ¼: { position.get('avg_px'):.2f} USDT")
            if position.get('mark_px'):
                content_parts.append(f"â–¸ å¹³ä»“ä»·æ ¼: { position.get('mark_px'):.2f} USDT")
            content_parts.append(f"â–¸ å¼€ä»“æ•°é‡: {position['pos']} å¼ ")
            upl_ratio=round(position['upl_ratio']*100,2)
            open_time=datetime.fromtimestamp(position['open_time'] / 1000).strftime('%Y-%m-%d %H:%M:%S')
            close_time=datetime.fromtimestamp(position['close_time'] / 1000).strftime('%Y-%m-%d %H:%M:%S')

            content_parts.append(f"  å®ç°æ”¶ç›Šï¼š${position['upl']}({upl_ratio}%)")
            content_parts.append(f"  å¼€ä»“æ—¶é—´ï¼š{open_time}")
            content_parts.append(f"  å¹³ä»“æ—¶é—´ï¼š{close_time}")
            
            content = "\n".join(content_parts)

            signal=f'{"å¤šä»“" if position["posSide"] =="long" else "ç©ºä»“"} å·²å¹³ä»“',
            payload={
    "msg_type": "post",
    "content": {
        "post": {
            "zh_cn": {
                "title": f"AIå¹³ä»“é€šçŸ¥ ã€{signal}ã€‘ ï¼ˆ{self.inst_id}ï¼‰",
                "content": [
                    [{
                        "tag": "text",
                        "text":content
                    }]
                ]
            }
        }
    }
}

            # å‘é€POSTè¯·æ±‚ï¼ˆè®¾ç½®30ç§’è¶…æ—¶ï¼‰
            response = requests.post(
                self.feishu_webhook_url,
                json=payload,
                timeout=30
            )

            if response.status_code == 200:
                logger.info(f"âœ… é£ä¹¦é€šçŸ¥å·²å‘é€: {signal_text}")
            else:
                logger.warning(f"âš ï¸ é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥: HTTP {response.status_code}")
        except requests.exceptions.Timeout:
            logger.warning("âš ï¸ é£ä¹¦é€šçŸ¥å‘é€è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
        except Exception as e:
            logger.error(f"âŒ é£ä¹¦é€šçŸ¥å‘é€å¼‚å¸¸: {e}")
    def send_feishu_notification(self, current_price: float = None):
        """
        å‘é€é£ä¹¦é€šçŸ¥ï¼ˆå¼€ä»“/è°ƒæ•´æ­¢ç›ˆæ­¢æŸå†³ç­–ï¼‰- åå°çº¿ç¨‹å¼‚æ­¥æ‰§è¡Œ

        Args:
            current_price: å½“å‰ä»·æ ¼
        """
        # æ£€æŸ¥é£ä¹¦é€šçŸ¥æ˜¯å¦å¯ç”¨
        if not self.feishu_enabled or not self.feishu_webhook_url:
            return

        signal = self.analysis.get('signal')

        # åªæœ‰å¼€ä»“å’Œè°ƒæ•´æ­¢ç›ˆæ­¢æŸæ—¶æ‰å‘é€é€šçŸ¥
        if signal not in ['OPEN_LONG', 'OPEN_SHORT', 'ADJUST_STOP']:
            return

        # åœ¨åå°çº¿ç¨‹ä¸­å‘é€ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        def send_task():
            try:
                confidence = self.analysis.get('confidence', 0)
                reason = self.analysis.get('reason', 'æ— ç†ç”±è¯´æ˜')
                adjust_data = self.analysis.get('adjust_data', {})

                # æ ¹æ®ä¿¡å·ç±»å‹æ ¼å¼åŒ–å†…å®¹
                if signal == 'OPEN_LONG':
                    signal_text = " å¼€å¤šä»“"
                    size = self.analysis.get('size', 0)

                    # ä»adjust_dataæå–æ­¢ç›ˆæ­¢æŸä¿¡æ¯
                    tp_layers = adjust_data.get('take_profit', [])
                    sl_layers = adjust_data.get('stop_loss', [])

                    content_parts = [f"ã€{signal_text}ã€‘"]
                    content_parts.append(f"â–¸ äº¤æ˜“å¯¹: {self.inst_id}")
                    if current_price:
                        content_parts.append(f"â–¸ å¼€ä»“ä»·æ ¼: {current_price:.2f} USDT")
                    content_parts.append(f"â–¸ å¼€ä»“æ•°é‡: {size} å¼ ")

                    # æ˜¾ç¤ºæ­¢ç›ˆå±‚çº§
                    if tp_layers:
                        content_parts.append(f"â–¸ æ­¢ç›ˆï¼ˆ{len(tp_layers)}å±‚ï¼‰:")
                        for i, layer in enumerate(tp_layers, 1):
                            content_parts.append(f"  #{i}: {layer['size']}å¼  @ {layer['price']:.2f}")

                    # æ˜¾ç¤ºæ­¢æŸå±‚çº§
                    if sl_layers:
                        content_parts.append(f"â–¸ æ­¢æŸï¼ˆ{len(sl_layers)}å±‚ï¼‰:")
                        for i, layer in enumerate(sl_layers, 1):
                            content_parts.append(f"  #{i}: {layer['size']}å¼  @ {layer['price']:.2f}")

                    content_parts.append(f"â–¸ ç½®ä¿¡åº¦: {confidence}%")
                    content_parts.append(f"â–¸ æ æ†å€æ•°: {self.leverage}x")
                    content_parts.append(f"â–¸ å†³ç­–ç†ç”±: {reason[:100]}...")

                    content = "\n".join(content_parts)

                elif signal == 'OPEN_SHORT':
                    signal_text = " å¼€ç©ºä»“"
                    size = self.analysis.get('size', 0)

                    # ä»adjust_dataæå–æ­¢ç›ˆæ­¢æŸä¿¡æ¯
                    tp_layers = adjust_data.get('take_profit', [])
                    sl_layers = adjust_data.get('stop_loss', [])

                    content_parts = [f"ã€{signal_text}ã€‘"]
                    content_parts.append(f"â–¸ äº¤æ˜“å¯¹: {self.inst_id}")
                    if current_price:
                        content_parts.append(f"â–¸ å¼€ä»“ä»·æ ¼: {current_price:.2f} USDT")
                    content_parts.append(f"â–¸ å¼€ä»“æ•°é‡: {size} å¼ ")

                    # æ˜¾ç¤ºæ­¢ç›ˆå±‚çº§
                    if tp_layers:
                        content_parts.append(f"â–¸ æ­¢ç›ˆï¼ˆ{len(tp_layers)}å±‚ï¼‰:")
                        for i, layer in enumerate(tp_layers, 1):
                            content_parts.append(f"  #{i}: {layer['size']}å¼  @ {layer['price']:.2f}")

                    # æ˜¾ç¤ºæ­¢æŸå±‚çº§
                    if sl_layers:
                        content_parts.append(f"â–¸ æ­¢æŸï¼ˆ{len(sl_layers)}å±‚ï¼‰:")
                        for i, layer in enumerate(sl_layers, 1):
                            content_parts.append(f"  #{i}: {layer['size']}å¼  @ {layer['price']:.2f}")

                    content_parts.append(f"â–¸ ç½®ä¿¡åº¦: {confidence}%")
                    content_parts.append(f"â–¸ æ æ†å€æ•°: {self.leverage}x")
                    content_parts.append(f"â–¸ å†³ç­–ç†ç”±: {reason[:100]}...")

                    content = "\n".join(content_parts)

                elif signal == 'ADJUST_STOP':
                    signal_text = " è°ƒæ•´æ­¢ç›ˆæ­¢æŸ"

                    # ä»adjust_dataæå–æ­¢ç›ˆæ­¢æŸä¿¡æ¯
                    tp_layers = adjust_data.get('take_profit', [])
                    sl_layers = adjust_data.get('stop_loss', [])

                    content_parts = [f"ã€{signal_text}ã€‘"]
                    content_parts.append(f"â–¸ äº¤æ˜“å¯¹: {self.inst_id}")
                    if current_price:
                        content_parts.append(f"â–¸ å½“å‰ä»·æ ¼: {current_price:.2f} USDT")

                    # æ˜¾ç¤ºæ­¢ç›ˆå±‚çº§
                    if tp_layers:
                        content_parts.append(f"â–¸ æ–°æ­¢ç›ˆï¼ˆ{len(tp_layers)}å±‚ï¼‰:")
                        for i, layer in enumerate(tp_layers, 1):
                            content_parts.append(f"  #{i}: {layer['size']}å¼  @ {layer['price']:.2f}")

                    # æ˜¾ç¤ºæ­¢æŸå±‚çº§
                    if sl_layers:
                        content_parts.append(f"â–¸ æ–°æ­¢æŸï¼ˆ{len(sl_layers)}å±‚ï¼‰:")
                        for i, layer in enumerate(sl_layers, 1):
                            content_parts.append(f"  #{i}: {layer['size']}å¼  @ {layer['price']:.2f}")

                    content_parts.append(f"â–¸ ç½®ä¿¡åº¦: {confidence}%")
                    content_parts.append(f"â–¸ å†³ç­–ç†ç”±: {reason[:100]}...")

                    content = "\n".join(content_parts)

                else:
                    return

                # æ„é€ é£ä¹¦æ¶ˆæ¯æ ¼å¼

                payload={
    "msg_type": "post",
    "content": {
        "post": {
            "zh_cn": {
                "title": f"AIäº¤æ˜“é€šçŸ¥ ã€{signal}ã€‘ ï¼ˆ{self.inst_id}ï¼‰",
                "content": [
                    [{
                        "tag": "text",
                        "text":content
                    }]
                ]
            }
        }
    }
}

                # å‘é€POSTè¯·æ±‚ï¼ˆè®¾ç½®30ç§’è¶…æ—¶ï¼‰
                response = requests.post(
                    self.feishu_webhook_url,
                    json=payload,
                    timeout=30
                )

                if response.status_code == 200:
                    logger.info(f"âœ… é£ä¹¦é€šçŸ¥å·²å‘é€: {signal_text}")
                else:
                    logger.warning(f"âš ï¸ é£ä¹¦é€šçŸ¥å‘é€å¤±è´¥: HTTP {response.status_code}")

            except requests.exceptions.Timeout:
                logger.warning("âš ï¸ é£ä¹¦é€šçŸ¥å‘é€è¶…æ—¶ï¼ˆ30ç§’ï¼‰")
            except Exception as e:
                logger.error(f"âŒ é£ä¹¦é€šçŸ¥å‘é€å¼‚å¸¸: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹å‘é€ï¼ˆdaemon=Trueï¼Œä¸é˜»å¡ä¸»ç¨‹åºé€€å‡ºï¼‰
        notification_thread = threading.Thread(
            target=send_task,
            daemon=True,
            name="feishu-notification"
        )
        notification_thread.start()

    def _load_decision_history(self):
        """
        ä»æœ¬åœ°JSONæ–‡ä»¶åŠ è½½å†å²AIå†³ç­–

        æ–‡ä»¶æ ¼å¼: [{"content": "...", "timestamp": "2025-10-27 16:30:45"}, ...]
        """
        try:
            # ç¡®ä¿dataç›®å½•å­˜åœ¨
            data_dir = os.path.dirname(self.ai_decision_history_file)
            if not os.path.exists(data_dir):
                os.makedirs(data_dir, exist_ok=True)
                logger.info(f"âœ“ åˆ›å»ºæ•°æ®ç›®å½•: {data_dir}")

            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç©ºæ–‡ä»¶
            if not os.path.exists(self.ai_decision_history_file):
                with open(self.ai_decision_history_file, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                logger.info(f"âœ“ åˆ›å»ºå†å²å†³ç­–æ–‡ä»¶: {self.ai_decision_history_file}")
                return

            # è¯»å–æ–‡ä»¶
            with open(self.ai_decision_history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # éªŒè¯æ•°æ®æ ¼å¼
            if isinstance(data, list):
                # åªä¿ç•™æœ€è¿‘10æ¡ï¼ˆé˜²æ­¢æ–‡ä»¶è¿‡å¤§ï¼‰
                self.ai_decision_history = data[-10:]
                logger.debug(f"âœ“ ä»æ–‡ä»¶åŠ è½½äº† {len(self.ai_decision_history)} æ¡å†å²å†³ç­–")
            else:
                logger.warning(f"âš ï¸ å†å²å†³ç­–æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ›listï¼Œå¾—åˆ°{type(data)}")
                self.ai_decision_history = []

        except json.JSONDecodeError as e:
            logger.error(f"âŒ å†å²å†³ç­–æ–‡ä»¶JSONè§£æå¤±è´¥: {e}")
            self.ai_decision_history = []
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å†å²å†³ç­–å¤±è´¥: {e}")
            self.ai_decision_history = []

    def _save_decision_history(self):
        """
        ä¿å­˜å†å²AIå†³ç­–åˆ°æœ¬åœ°JSONæ–‡ä»¶ï¼ˆåå°çº¿ç¨‹æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰

        åªä¿ç•™æœ€è¿‘10æ¡å†³ç­–
        """
        def save_task():
            try:
                # ç¡®ä¿dataç›®å½•å­˜åœ¨
                data_dir = os.path.dirname(self.ai_decision_history_file)
                if not os.path.exists(data_dir):
                    os.makedirs(data_dir, exist_ok=True)

                # åªä¿ç•™æœ€è¿‘10æ¡
                history_to_save = self.ai_decision_history[-10:] if len(self.ai_decision_history) > 10 else self.ai_decision_history

                # å†™å…¥æ–‡ä»¶
                with open(self.ai_decision_history_file, 'w', encoding='utf-8') as f:
                    json.dump(history_to_save, f, ensure_ascii=False, indent=2)

                logger.debug(f"âœ“ å†å²å†³ç­–å·²ä¿å­˜åˆ°æ–‡ä»¶: {len(history_to_save)} æ¡")

            except Exception as e:
                logger.error(f"âŒ ä¿å­˜å†å²å†³ç­–å¤±è´¥: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹ä¿å­˜ï¼ˆdaemon=Trueï¼Œä¸é˜»å¡ä¸»ç¨‹åºé€€å‡ºï¼‰
        save_thread = threading.Thread(
            target=save_task,
            daemon=True,
            name="save-decision-history"
        )
        save_thread.start()

    async def start_realtime_collector(self):
        """å¯åŠ¨å®æ—¶æ•°æ®é‡‡é›†ï¼ˆåå°ä»»åŠ¡ï¼‰"""
        if self.realtime_collector:
            logger.info("ğŸš€ å¯åŠ¨å®æ—¶æ•°æ®é‡‡é›†...")
            self.collector_task = asyncio.create_task(self.realtime_collector.start())
            await asyncio.sleep(3)  # ç­‰å¾…æ•°æ®ç§¯ç´¯
            logger.success("âœ“ å®æ—¶æ•°æ®é‡‡é›†å·²å¯åŠ¨")

    def update_balance_cache(self):
        """
        åå°çº¿ç¨‹ï¼šå®šæœŸæ›´æ–°è´¦æˆ·ä½™é¢ç¼“å­˜
        æ¯30ç§’æ›´æ–°ä¸€æ¬¡ï¼Œé¿å…äº¤æ˜“æ—¶å®æ—¶è°ƒç”¨APIå½±å“æ•ˆç‡
        """
        while not self.stop_balance_thread:
            try:
                # è·å–æœ€æ–°ä½™é¢
                balance = self.account_api.get_usdt_balance()
                if balance['success']:
                    # ç›´æ¥æ›´æ–°ï¼Œæ— éœ€é”ï¼ˆfloatè¯»å†™åŸºæœ¬æ˜¯åŸå­æ€§çš„ï¼‰
                    self.cached_balance = balance.get('availEq', 0)
                    self.balance_last_update = datetime.now()
                    logger.debug(f"âœ“ ä½™é¢ç¼“å­˜å·²æ›´æ–°: {self.cached_balance:.2f} USDT")
                else:
                    logger.warning(f"âš ï¸ ä½™é¢æ›´æ–°å¤±è´¥: {balance}")
            except Exception as e:
                logger.error(f"âŒ ä½™é¢æ›´æ–°å¼‚å¸¸: {e}")

            # æ¯30ç§’æ›´æ–°ä¸€æ¬¡
            time.sleep(30)

    def start_balance_update_thread(self):
        """å¯åŠ¨ä½™é¢æ›´æ–°åå°çº¿ç¨‹"""
        # ç«‹å³è·å–ä¸€æ¬¡ä½™é¢
        try:
            balance = self.account_api.get_usdt_balance()
            if balance['success']:
                self.cached_balance = balance.get('availEq', 0)
                self.balance_last_update = datetime.now()
                logger.info(f"ğŸ’° åˆå§‹ä½™é¢: {self.cached_balance:.2f} USDT")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹ä½™é¢è·å–å¤±è´¥: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹
        self.balance_update_thread = threading.Thread(
            target=self.update_balance_cache,
            daemon=True,
            name="balance-updater"
        )
        self.balance_update_thread.start()
        logger.info("âœ“ ä½™é¢æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯30ç§’æ›´æ–°ï¼‰")

    def get_cached_balance(self) -> float:
        """
        è·å–ç¼“å­˜çš„è´¦æˆ·ä½™é¢ï¼ˆæ— é”è®¿é—®ï¼Œæé«˜äº¤æ˜“æ•ˆç‡ï¼‰

        Returns:
            ç¼“å­˜çš„USDTä½™é¢
        """
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆä»…æç¤ºï¼Œä¸å½±å“ä½¿ç”¨ï¼‰
        if self.balance_last_update:
            age_seconds = (datetime.now() - self.balance_last_update).total_seconds()
            if age_seconds > 60:
                logger.warning(f"âš ï¸ ä½™é¢ç¼“å­˜å·²è¿‡æœŸ ({age_seconds:.0f}ç§’)ï¼Œå¯èƒ½ä¸å‡†ç¡®")
        else:
            logger.warning("âš ï¸ ä½™é¢ç¼“å­˜æœªåˆå§‹åŒ–")

        return self.cached_balance

    def stop_balance_update_thread(self):
        """åœæ­¢ä½™é¢æ›´æ–°çº¿ç¨‹"""
        if self.balance_update_thread and self.balance_update_thread.is_alive():
            self.stop_balance_thread = True
            self.balance_update_thread.join(timeout=5)
            logger.info("âœ“ ä½™é¢æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def update_position_cache(self):
        """
        åå°çº¿ç¨‹ï¼šå®šæœŸæ›´æ–°ä»“ä½ç¼“å­˜ï¼Œå…³è”AIå†³ç­–å†å²
        æ¯20ç§’æ›´æ–°ä¸€æ¬¡
        """
        while not self.stop_position_thread:
            try:
                result = self.position_api.get_contract_positions(inst_type='SWAP', inst_id=self.inst_id)
                if result['code'] == '0':
                    positions = result.get('data', [])

                    # å…³è”å†³ç­–å†å²
                    enriched_positions = []
                    for pos in positions:
                        if float(pos.get('pos', 0)) == 0:
                            continue

                        pos_id = str(pos.get('cTime'))

                        # ä»æ•°æ®åº“æŸ¥è¯¢å†³ç­–å†å²
                        decisions = self.data_manager.get_decisions_by_pos_id(
                            pos_id,
                            api_key=config.API_KEY if config.API_KEY else 'default'
                        )

                        # åˆå¹¶ä»“ä½å’Œå†³ç­–å†å²
                        enriched_pos = {
                            **pos,
                            'decisions': decisions,
                            'decision_count': len(decisions),
                            'last_decision': decisions[-1] if decisions else None,
                            'open_reason': decisions[0]['reason'] if decisions else None,
                            'adjustments': [d for d in decisions if d.get('action') == 'ADJUST_STOP']
                        }
                        enriched_positions.append(enriched_pos)
                    for lastPosition  in  self.cached_positions:
                        if str(lastPosition['cTime']) not in [str(position['cTime']) for position in enriched_positions]:
                            #å‘é€é£ä¹¦å¹³ä»“é€šçŸ¥
                            self.send_feishu_content(str(lastPosition['cTime']))
                    self.cached_positions = enriched_positions
                    self.positions_last_update = datetime.now()
                    logger.debug(f"âœ“ ä»“ä½ç¼“å­˜å·²æ›´æ–°: {len(self.cached_positions)}ä¸ªæŒä»“")
                else:
                    logger.warning(f"âš ï¸ ä»“ä½æ›´æ–°å¤±è´¥: {result.get('msg')}")
            except Exception as e:
                logger.error(f"âŒ ä»“ä½æ›´æ–°å¼‚å¸¸: {e}")

            time.sleep(20)

    def start_position_update_thread(self):
        """å¯åŠ¨ä»“ä½æ›´æ–°åå°çº¿ç¨‹"""
        # ç«‹å³è·å–ä¸€æ¬¡ä»“ä½
        try:
            result = self.position_api.get_contract_positions(inst_type='SWAP', inst_id=self.inst_id)
            if result['code'] == '0':
                positions = result.get('data', [])
                self.cached_positions = [p for p in positions if float(p.get('pos', 0)) != 0]
                self.positions_last_update = datetime.now()
                logger.info(f"ğŸ“Š åˆå§‹ä»“ä½: {len(self.cached_positions)}ä¸ªæŒä»“")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹ä»“ä½è·å–å¤±è´¥: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹
        self.position_update_thread = threading.Thread(
            target=self.update_position_cache,
            daemon=True,
            name="position-updater"
        )
        self.position_update_thread.start()
        logger.info("âœ“ ä»“ä½æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯20ç§’æ›´æ–°ï¼‰")

    def get_cached_positions(self) -> list:
        """
        è·å–ç¼“å­˜çš„ä»“ä½æ•°æ®ï¼ˆæ— é”è®¿é—®ï¼Œæé«˜äº¤æ˜“æ•ˆç‡ï¼‰

        Returns:
            ç¼“å­˜çš„æŒä»“åˆ—è¡¨
        """
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if self.positions_last_update:
            age_seconds = (datetime.now() - self.positions_last_update).total_seconds()
            if age_seconds > 60:
                logger.warning(f"âš ï¸ ä»“ä½ç¼“å­˜å·²è¿‡æœŸ ({age_seconds:.0f}ç§’)ï¼Œå¯èƒ½ä¸å‡†ç¡®")
        else:
            logger.warning("âš ï¸ ä»“ä½ç¼“å­˜æœªåˆå§‹åŒ–")

        return self.cached_positions

    def stop_position_update_thread(self):
        """åœæ­¢ä»“ä½æ›´æ–°çº¿ç¨‹"""
        if self.position_update_thread and self.position_update_thread.is_alive():
            self.stop_position_thread = True
            self.position_update_thread.join(timeout=5)
            logger.info("âœ“ ä»“ä½æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def update_stop_order_cache(self):
        """
        åå°çº¿ç¨‹ï¼šå®šæœŸæ›´æ–°æ­¢ç›ˆæ­¢æŸå§”æ‰˜è®¢å•ç¼“å­˜

        æ­¢ç›ˆï¼šä»æ™®é€šæŒ‚å•è·å–ï¼ˆlimit ordersï¼ŒæŒ‚å•æ¨¡å¼ï¼‰
        æ­¢æŸï¼šä»ç®—æ³•è®¢å•è·å–ï¼ˆconditional ordersï¼Œæ¡ä»¶å•ï¼‰

        æ¯20ç§’æ›´æ–°ä¸€æ¬¡
        """
        while not self.stop_stop_order_thread:
            try:
                # 1. è·å–æ™®é€šæŒ‚å•ï¼ˆæ­¢ç›ˆç”¨é™ä»·å•ï¼‰
                limit_orders = []
                try:
                    limit_result = self.trade_api.get_orders_pending(
                        inst_id=self.inst_id,
                        ord_type='limit',
                        state='live'  # æœªæˆäº¤è®¢å•
                    )
                    if limit_result['code'] == '0':
                        limit_orders = limit_result.get('data', [])
                        logger.debug(f"âœ“ è·å–åˆ° {len(limit_orders)} ä¸ªé™ä»·å•ï¼ˆæ­¢ç›ˆï¼‰")
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–é™ä»·å•å¤±è´¥: {e}")

                # 2. è·å–ç®—æ³•è®¢å•ï¼ˆæ­¢æŸç”¨æ¡ä»¶å•ï¼‰
                algo_orders = []
                try:
                    algo_result = self.trade_api.get_algo_order_list(
                        ord_type='conditional',
                        inst_id=self.inst_id
                    )
                    if algo_result['code'] == '0':
                        algo_orders = algo_result.get('data', [])
                        logger.debug(f"âœ“ è·å–åˆ° {len(algo_orders)} ä¸ªæ¡ä»¶å•ï¼ˆæ­¢æŸï¼‰")
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–æ¡ä»¶å•å¤±è´¥: {e}")

                # 3. åˆå¹¶è§£æ
                self.cached_stop_orders = self._parse_stop_orders(limit_orders, algo_orders)
                self.stop_orders_last_update = datetime.now()
                logger.debug(f"âœ“ æ­¢ç›ˆæ­¢æŸè®¢å•ç¼“å­˜å·²æ›´æ–°: {len(self.cached_stop_orders)}ä¸ªæ–¹å‘")

            except Exception as e:
                logger.error(f"âŒ æ­¢ç›ˆæ­¢æŸè®¢å•æ›´æ–°å¼‚å¸¸: {e}")

            time.sleep(20)

    def _parse_stop_orders(self, limit_orders: list, algo_orders: list) -> dict:
        """
        è§£ææ­¢ç›ˆæ­¢æŸè®¢å•ï¼ˆåˆ†åˆ«å¤„ç†é™ä»·å•å’Œæ¡ä»¶å•ï¼‰

        Args:
            limit_orders: æ™®é€šé™ä»·å•åˆ—è¡¨ï¼ˆæ­¢ç›ˆï¼‰
            algo_orders: ç®—æ³•æ¡ä»¶å•åˆ—è¡¨ï¼ˆæ­¢æŸï¼‰

        Returns:
            è§£æåçš„å­—å…¸ {pos_side: {'stop_loss': [...], 'take_profit': [...]}}
            æ¯ä¸ªåˆ—è¡¨åŒ…å«å¤šå±‚ä¿¡æ¯ï¼š[{'order_id': ..., 'price': ..., 'size': ...}, ...]
        """
        parsed = {}

        # 1. è§£æé™ä»·å•ï¼ˆæ­¢ç›ˆï¼‰
        for order in limit_orders:
            pos_side = order.get('posSide')
            if not pos_side:
                continue

            if pos_side not in parsed:
                parsed[pos_side] = {'take_profit': [], 'stop_loss': []}

            # é™ä»·å•å­—æ®µï¼šordId, px (ä»·æ ¼), sz (æ•°é‡), side
            order_info = {
                'order_id': order.get('ordId'),
                'price': float(order.get('px', 0)),
                'size': float(order.get('sz', 0)),
                'order_type': 'limit'
            }

            # æ ¹æ®sideåˆ¤æ–­æ˜¯æ­¢ç›ˆè®¢å•
            # å¤šå¤´æ­¢ç›ˆï¼šå–å‡ºå¹³ä»“ï¼Œç©ºå¤´æ­¢ç›ˆï¼šä¹°å…¥å¹³ä»“
            side = order.get('side')
            if (pos_side == 'long' and side == 'sell') or (pos_side == 'short' and side == 'buy'):
                parsed[pos_side]['take_profit'].append(order_info)

        # 2. è§£æç®—æ³•è®¢å•ï¼ˆæ­¢æŸï¼‰
        for order in algo_orders:
            pos_side = order.get('posSide')
            if not pos_side:
                continue

            if pos_side not in parsed:
                parsed[pos_side] = {'take_profit': [], 'stop_loss': []}

            # æ¡ä»¶å•å­—æ®µï¼šalgoId, slTriggerPx (æ­¢æŸè§¦å‘ä»·), sz
            sl_trigger_px = order.get('slTriggerPx')
            if sl_trigger_px:
                order_info = {
                    'order_id': order.get('algoId'),
                    'price': float(sl_trigger_px),
                    'size': float(order.get('sz', 0)),
                    'order_type': 'conditional'
                }
                parsed[pos_side]['stop_loss'].append(order_info)

        # 3. æŒ‰ä»·æ ¼æ’åºï¼ˆæ­¢ç›ˆï¼šä»é«˜åˆ°ä½ï¼Œæ­¢æŸï¼šä»ä½åˆ°é«˜ï¼‰
        for pos_side, orders in parsed.items():
            # æ­¢ç›ˆæ’åºï¼ˆå¤šå¤´ä»é«˜åˆ°ä½ï¼Œç©ºå¤´ä»ä½åˆ°é«˜ï¼‰
            if orders['take_profit']:
                reverse = (pos_side == 'long')
                orders['take_profit'].sort(key=lambda x: x['price'], reverse=reverse)

            # æ­¢æŸæ’åºï¼ˆå¤šå¤´ä»é«˜åˆ°ä½ï¼Œç©ºå¤´ä»ä½åˆ°é«˜ï¼‰
            if orders['stop_loss']:
                reverse = (pos_side == 'long')
                orders['stop_loss'].sort(key=lambda x: x['price'], reverse=reverse)

        return parsed

    def start_stop_order_update_thread(self):
        """å¯åŠ¨æ­¢ç›ˆæ­¢æŸè®¢å•æ›´æ–°åå°çº¿ç¨‹"""
        # ç«‹å³è·å–ä¸€æ¬¡è®¢å•
        try:
            # 1. è·å–æ™®é€šæŒ‚å•ï¼ˆæ­¢ç›ˆï¼‰
            limit_orders = []
            try:
                limit_result = self.trade_api.get_orders_pending(
                    inst_id=self.inst_id,
                    ord_type='limit',
                    state='live'
                )
                if limit_result['code'] == '0':
                    limit_orders = limit_result.get('data', [])
            except Exception as e:
                logger.warning(f"âš ï¸ åˆå§‹è·å–é™ä»·å•å¤±è´¥: {e}")

            # 2. è·å–ç®—æ³•è®¢å•ï¼ˆæ­¢æŸï¼‰
            algo_orders = []
            try:
                algo_result = self.trade_api.get_algo_order_list(
                    ord_type='conditional',
                    inst_id=self.inst_id
                )
                if algo_result['code'] == '0':
                    algo_orders = algo_result.get('data', [])
            except Exception as e:
                logger.warning(f"âš ï¸ åˆå§‹è·å–æ¡ä»¶å•å¤±è´¥: {e}")

            # 3. åˆå¹¶è§£æ
            self.cached_stop_orders = self._parse_stop_orders(limit_orders, algo_orders)
            self.stop_orders_last_update = datetime.now()

            # ç»Ÿè®¡å±‚æ•°
            total_tp_layers = sum(len(orders.get('take_profit', [])) for orders in self.cached_stop_orders.values())
            total_sl_layers = sum(len(orders.get('stop_loss', [])) for orders in self.cached_stop_orders.values())

            logger.info(
                f"ğŸ“‹ åˆå§‹æ­¢ç›ˆæ­¢æŸè®¢å•: {len(self.cached_stop_orders)}ä¸ªæ–¹å‘, "
                f"æ­¢ç›ˆ{total_tp_layers}å±‚, æ­¢æŸ{total_sl_layers}å±‚"
            )
        except Exception as e:
            logger.error(f"âŒ åˆå§‹æ­¢ç›ˆæ­¢æŸè®¢å•è·å–å¤±è´¥: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹
        self.stop_order_update_thread = threading.Thread(
            target=self.update_stop_order_cache,
            daemon=True,
            name="stop-order-updater"
        )
        self.stop_order_update_thread.start()
        logger.info("âœ“ æ­¢ç›ˆæ­¢æŸè®¢å•æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯20ç§’æ›´æ–°ï¼‰")

    def get_cached_stop_orders(self) -> dict:
        """
        è·å–ç¼“å­˜çš„æ­¢ç›ˆæ­¢æŸè®¢å•æ•°æ®

        Returns:
            ç¼“å­˜çš„è®¢å•å­—å…¸
        """
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if self.stop_orders_last_update:
            age_seconds = (datetime.now() - self.stop_orders_last_update).total_seconds()
            if age_seconds > 60:
                logger.warning(f"âš ï¸ æ­¢ç›ˆæ­¢æŸè®¢å•ç¼“å­˜å·²è¿‡æœŸ ({age_seconds:.0f}ç§’)ï¼Œå¯èƒ½ä¸å‡†ç¡®")
        else:
            logger.warning("âš ï¸ æ­¢ç›ˆæ­¢æŸè®¢å•ç¼“å­˜æœªåˆå§‹åŒ–")

        return self.cached_stop_orders

    def stop_stop_order_update_thread(self):
        """åœæ­¢æ­¢ç›ˆæ­¢æŸè®¢å•æ›´æ–°çº¿ç¨‹"""
        if self.stop_order_update_thread and self.stop_order_update_thread.is_alive():
            self.stop_stop_order_thread = True
            self.stop_order_update_thread.join(timeout=5)
            logger.info("âœ“ æ­¢ç›ˆæ­¢æŸè®¢å•æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def update_position_history_cache(self):
        """
        åå°çº¿ç¨‹ï¼šå®šæœŸæ›´æ–°å†å²ä»“ä½ç¼“å­˜

        æµç¨‹ï¼š
        1. é€šè¿‡APIè·å–OKXå†å²æŒä»“è®°å½•ï¼ˆå·²å¹³ä»“ï¼‰
        2. ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆINSERT OR REPLACEï¼Œé¿å…é‡å¤ï¼‰
        3. æ›´æ–°å†…å­˜ç¼“å­˜ï¼ˆå†å²ä»“ä½ + ç»Ÿè®¡æ•°æ®ï¼‰

        æ¯30ç§’æ‰§è¡Œä¸€æ¬¡
        """
        while not self.stop_history_thread:
            try:
                # 1. è·å–OKXå†å²æŒä»“è®°å½•ï¼ˆå·²å¹³ä»“ï¼‰
                history_result = self.position_api.get_positions_history(
                    inst_type='SWAP',
                    inst_id=self.inst_id,
                    limit='100'  # è·å–æœ€è¿‘100æ¡å†å²è®°å½•
                )

                # 2. ä¿å­˜OKXå†å²æŒä»“åˆ°æ•°æ®åº“ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰
                if history_result and history_result.get('code') == '0' and history_result.get('data'):
                    okx_history = history_result['data']

                    # å‡†å¤‡æ‰¹é‡æ•°æ®
                    batch_data = []
                    for pos in okx_history:
                        try:
                            inst_id = pos.get('instId', '')
                            pos_side = pos.get('posSide', '')

                            # ä½¿ç”¨uTimeä½œä¸ºå¹³ä»“æ—¶é—´ï¼ˆOKXè¿”å›çš„å®é™…å¹³ä»“æ—¶é—´ï¼‰
                            close_time = int(pos.get('uTime', 0))
                            realized_pnl = float(pos.get('realizedPnl', 0)) if pos.get('realizedPnl') else float(pos.get('pnl', 0))

                            # æå–å­—æ®µ
                            pos_size = float(pos.get('closePosSize', 0))
                            avg_px = float(pos.get('openAvgPx', 0))
                            mark_px = float(pos.get('closeAvgPx', 0))
                            upl = realized_pnl
                            upl_ratio = float(pos.get('pnlRatio', 0))
                            leverage = pos.get('lever', '20')
                            margin = float(pos.get('margin', 0)) if pos.get('margin') else None
                            imr = float(pos.get('imr', 0)) if pos.get('imr') else None
                            fee = float(pos.get('fee', 0)) if pos.get('fee') else 0.0
                            open_time = int(pos.get('cTime', 0)) if pos.get('cTime') else None
                            close_total_pos = float(pos.get('closeTotalPos', 0)) if pos.get('closeTotalPos') else None

                            # æ·»åŠ åˆ°æ‰¹é‡æ•°æ®
                            batch_data.append((
                                inst_id, pos_side, pos_size, avg_px, mark_px, upl, upl_ratio,
                                leverage, margin, imr, fee, open_time, close_time, realized_pnl, close_total_pos
                            ))

                        except Exception as e:
                            logger.debug(f"å¤„ç†OKXå†å²æŒä»“å¤±è´¥: {e}")
                            continue

                    # æ‰¹é‡ä¿å­˜ï¼ˆä¸€æ¬¡æ€§æäº¤ï¼‰
                    if batch_data:
                        success_count, total_count = self.data_manager.save_closed_positions_batch(
                            batch_data,
                            api_key=config.API_KEY if config.API_KEY else 'default'
                        )
                        logger.debug(f"âœ“ æ‰¹é‡ä¿å­˜å†å²æŒä»“: {success_count}/{total_count} æ¡")

                        # å¤ç›˜é€»è¾‘ï¼šæ£€æŸ¥æ¯ä¸ªä»“ä½æ˜¯å¦éœ€è¦ç”Ÿæˆå¤ç›˜æ€»ç»“
                        if self.ai_client:
                            for pos in okx_history:
                                try:
                                    inst_id = pos.get('instId', '')
                                    pos_side = pos.get('posSide', '')
                                    open_time = int(pos.get('cTime', 0)) if pos.get('cTime') else None
                                    close_time = int(pos.get('uTime', 0))

                                    if not open_time:
                                        continue
                                        
                                    if pos['type']!='2':
                                        continue
                                        

                                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤ç›˜æ€»ç»“
                                    existing_review = self.data_manager.get_position_review_summary(
                                        inst_id=inst_id,
                                        pos_side=pos_side,
                                        open_time=open_time,
                                        api_key=config.API_KEY if config.API_KEY else 'default'
                                    )

                                    if existing_review:
                                        logger.debug(f"â© ä»“ä½å·²æœ‰å¤ç›˜æ€»ç»“ï¼Œè·³è¿‡: {inst_id} {pos_side} open_time={open_time}")
                                        continue

                                    # å‡†å¤‡ä»“ä½æ•°æ®
                                    position_data = {
                                        'inst_id': inst_id,
                                        'pos_side': pos_side,
                                        'pos':  float(pos.get('closeTotalPos', 0)) if pos.get('closeTotalPos') else None,
                                        'avg_px': float(pos.get('openAvgPx', 0)),
                                        'mark_px': float(pos.get('closeAvgPx', 0)),
                                        'upl': float(pos.get('realizedPnl', 0)) if pos.get('realizedPnl') else float(pos.get('pnl', 0)),
                                        'upl_ratio': float(pos.get('pnlRatio', 0)),
                                        'fee': float(pos.get('fee', 0)) if pos.get('fee') else 0.0,
                                        'open_time': open_time,
                                        'close_time': close_time,
                                        'realized_pnl': float(pos.get('realizedPnl', 0)) if pos.get('realizedPnl') else float(pos.get('pnl', 0)),
                                        'holding_duration_seconds': (close_time - open_time) / 1000 if open_time and close_time else 0
                                    }

                                    # è·å–å†³ç­–å†å²
                                    pos_id = str(open_time)
                                    decisions = self.data_manager.get_decisions_by_pos_id(
                                        pos_id,
                                        api_key=config.API_KEY if config.API_KEY else 'default'
                                    )

                                    # è·å–å¹³ä»“å‰çš„5åˆ†é’ŸKçº¿æ•°æ®
                                    # ä½¿ç”¨ end_time å‚æ•°è·å–å¹³ä»“æ—¶é—´ä¹‹å‰çš„Kçº¿
                                    klines = self.data_manager.get_recent_klines(
                                        inst_id=inst_id,
                                        bar='5m',
                                        limit=80,  # è·å–20æ ¹Kçº¿
                                        end_time=close_time+60*30*1000  # åªè·å–å¹³ä»“æ—¶é—´ä¹‹å‰çš„Kçº¿
                                    )
                                    
                                    if not decisions:
                                        continue

                                    # ç”Ÿæˆå¤ç›˜æ€»ç»“ï¼ˆåŒæ­¥è°ƒç”¨ï¼‰
                                    logger.info(f"ğŸ“ æ­£åœ¨ä¸ºä»“ä½ç”Ÿæˆå¤ç›˜: {inst_id} {pos_side} open_time={open_time}")
                                    review_summary = self.generate_position_review(
                                        position_data=position_data,
                                        decisions=decisions,
                                        klines=klines  # å·²ç»æ˜¯å¹³ä»“å‰çš„Kçº¿
                                    )

                                    # ä¿å­˜å¤ç›˜æ€»ç»“åˆ°æ•°æ®åº“
                                    if review_summary and not review_summary.startswith('å¤ç›˜ç”Ÿæˆå¤±è´¥') and not review_summary.startswith('å¤ç›˜ç”Ÿæˆå¼‚å¸¸'):
                                        success = self.data_manager.update_position_review_summary(
                                            inst_id=inst_id,
                                            pos_side=pos_side,
                                            open_time=open_time,
                                            review_summary=review_summary,
                                            api_key=config.API_KEY if config.API_KEY else 'default'
                                        )
                                        if success:
                                            logger.success(f"âœ… å¤ç›˜æ€»ç»“å·²ä¿å­˜: {inst_id} {pos_side}")
                                        else:
                                            logger.warning(f"âš ï¸ å¤ç›˜æ€»ç»“ä¿å­˜å¤±è´¥: {inst_id} {pos_side}")

                                except Exception as e:
                                    logger.error(f"âŒ ç”Ÿæˆä»“ä½å¤ç›˜å¤±è´¥: {e}")
                                    import traceback
                                    logger.debug(traceback.format_exc())
                                    continue


                # 3. æ›´æ–°ç¼“å­˜çš„å†å²ä»“ä½å’Œç»Ÿè®¡æ•°æ®ï¼ˆä»æ•°æ®åº“æŸ¥è¯¢å¹¶å…³è”å†³ç­–ï¼‰
                historical_positions = self.data_manager.get_recent_closed_positions(
                    inst_id=self.inst_id,
                    limit=10,
                    api_key=config.API_KEY if config.API_KEY else 'default'
                )

                # å…³è”å†³ç­–å†å²
                for pos in historical_positions:
                    pos_id = str(pos.get('open_time')  )
                    if pos_id:
                        decisions = self.data_manager.get_decisions_by_pos_id(
                            pos_id,
                            api_key=config.API_KEY if config.API_KEY else 'default'
                        )
                        pos['decisions'] = decisions
                        pos['decision_count'] = len(decisions)
                        pos['open_reason'] = decisions[0]['reason'] if decisions else None
                        pos['adjustments'] = [d for d in decisions if d.get('action') == 'ADJUST_STOP']

                self.cached_historical_positions = historical_positions
                self.cached_performance_stats = self.data_manager.get_performance_stats(
                    inst_id=self.inst_id,
                    days=30,
                    api_key=config.API_KEY if config.API_KEY else 'default'
                )
                self.history_last_update = datetime.now()

                logger.debug(
                    f"âœ“ å†å²ä»“ä½ç¼“å­˜å·²æ›´æ–°: {len(self.cached_historical_positions)}ç¬”å†å², "
                    f"30å¤©èƒœç‡: {self.cached_performance_stats.get('win_rate', 0):.1f}%"
                )

            except Exception as e:
                logger.error(f"âŒ å†å²ä»“ä½æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                logger.debug(traceback.format_exc())

            time.sleep(30)

    def start_position_history_thread(self):
        """å¯åŠ¨å†å²ä»“ä½æ›´æ–°åå°çº¿ç¨‹"""
        # ç«‹å³æ‰§è¡Œä¸€æ¬¡æ›´æ–°ï¼ˆé€šè¿‡APIè·å–OKXå†å²æŒä»“ï¼‰
        try:
            # è·å–OKXå†å²æŒä»“è®°å½•ï¼ˆå·²å¹³ä»“ï¼‰
            history_result = self.position_api.get_positions_history(
                inst_type='SWAP',
                inst_id=self.inst_id,
                limit='100'
            )

            # å¯¼å…¥OKXå†å²æŒä»“åˆ°æ•°æ®åº“ï¼ˆæ‰¹é‡ä¼˜åŒ–ï¼‰
            if history_result and history_result.get('code') == '0' and history_result.get('data'):
                okx_history = history_result['data']
                logger.info(f"ğŸ“Š ä»OKXè·å–åˆ° {len(okx_history)} æ¡å†å²æŒä»“è®°å½•")

                # å‡†å¤‡æ‰¹é‡æ•°æ®
                batch_data = []
                for pos in okx_history:
                    try:
                        inst_id = pos.get('instId', '')
                        pos_side = pos.get('posSide', '')

                        # ä½¿ç”¨uTimeä½œä¸ºå¹³ä»“æ—¶é—´ï¼ˆOKXè¿”å›çš„å®é™…å¹³ä»“æ—¶é—´ï¼‰
                        close_time = int(pos.get('uTime', 0))
                        if close_time == 0:
                            close_time = int(pos.get('cTime', 0))

                        realized_pnl = float(pos.get('realizedPnl', 0)) if pos.get('realizedPnl') else float(pos.get('pnl', 0))

                        # æå–å­—æ®µ
                        pos_size = float(pos.get('closePosSize', 0))
                        avg_px = float(pos.get('openAvgPx', 0))
                        mark_px = float(pos.get('closeAvgPx', 0))
                        upl = realized_pnl
                        upl_ratio = float(pos.get('pnlRatio', 0))
                        leverage = pos.get('lever', '20')
                        margin = float(pos.get('margin', 0)) if pos.get('margin') else None
                        imr = float(pos.get('imr', 0)) if pos.get('imr') else None
                        fee = float(pos.get('fee', 0)) if pos.get('fee') else 0.0
                        open_time = int(pos.get('cTime', 0)) if pos.get('cTime') else None
                        close_total_pos = float(pos.get('closeTotalPos', 0)) if pos.get('closeTotalPos') else None

                        # æ·»åŠ åˆ°æ‰¹é‡æ•°æ®
                        batch_data.append((
                            inst_id, pos_side, pos_size, avg_px, mark_px, upl, upl_ratio,
                            leverage, margin, imr, fee, open_time, close_time, realized_pnl, close_total_pos
                        ))

                    except Exception as e:
                        logger.debug(f"å¯¼å…¥å†å²æŒä»“å¤±è´¥: {e}")
                        continue

                # æ‰¹é‡ä¿å­˜ï¼ˆä¸€æ¬¡æ€§æäº¤ï¼‰
                if batch_data:
                    success_count, total_count = self.data_manager.save_closed_positions_batch(
                        batch_data,
                        api_key=config.API_KEY if config.API_KEY else 'default'
                    )
                    logger.info(f"âœ“ æˆåŠŸå¯¼å…¥ {success_count}/{total_count} æ¡OKXå†å²æŒä»“")

                    # å¤ç›˜é€»è¾‘ï¼šæ£€æŸ¥æ¯ä¸ªä»“ä½æ˜¯å¦éœ€è¦ç”Ÿæˆå¤ç›˜æ€»ç»“
                    if self.ai_client:
                        logger.info(f"ğŸ“ æ£€æŸ¥å†å²ä»“ä½å¤ç›˜éœ€æ±‚...")
                        review_count = 0
                        for pos in okx_history:
                            try:
                                inst_id = pos.get('instId', '')
                                pos_side = pos.get('posSide', '')
                                open_time = int(pos.get('cTime', 0)) if pos.get('cTime') else None
                                close_time = int(pos.get('uTime', 0))
                                if close_time == 0:
                                    close_time = int(pos.get('cTime', 0))

                                if not open_time:
                                    continue
                                if pos['type']!='2':
                                    continue

                                # æ£€æŸ¥æ˜¯å¦å·²æœ‰å¤ç›˜æ€»ç»“
                                existing_review = self.data_manager.get_position_review_summary(
                                    inst_id=inst_id,
                                    pos_side=pos_side,
                                    open_time=open_time,
                                    api_key=config.API_KEY if config.API_KEY else 'default'
                                )

                                if existing_review:
                                    continue

                                # é™åˆ¶åˆå§‹åŒ–æ—¶åªå¤ç›˜æœ€è¿‘5ç¬”
                                if review_count >= 5:
                                    logger.info(f"â¸ï¸ åˆå§‹åŒ–æ—¶å·²å¤ç›˜5ç¬”ï¼Œå‰©ä½™å°†ç”±åå°çº¿ç¨‹å¤„ç†")
                                    break

                                # å‡†å¤‡ä»“ä½æ•°æ®
                                position_data = {
                                    'inst_id': inst_id,
                                    'pos_side': pos_side,
                                    'pos': float(pos.get('closePosSize', 0)),
                                    'avg_px': float(pos.get('openAvgPx', 0)),
                                    'mark_px': float(pos.get('closeAvgPx', 0)),
                                    'upl': float(pos.get('realizedPnl', 0)) if pos.get('realizedPnl') else float(pos.get('pnl', 0)),
                                    'upl_ratio': float(pos.get('pnlRatio', 0)),
                                    'fee': float(pos.get('fee', 0)) if pos.get('fee') else 0.0,
                                    'open_time': open_time,
                                    'close_time': close_time,
                                    'realized_pnl': float(pos.get('realizedPnl', 0)) if pos.get('realizedPnl') else float(pos.get('pnl', 0)),
                                    'holding_duration_seconds': (close_time - open_time) / 1000 if open_time and close_time else 0
                                }

                                # è·å–å†³ç­–å†å²
                                pos_id = str(open_time)
                                decisions = self.data_manager.get_decisions_by_pos_id(
                                    pos_id,
                                    api_key=config.API_KEY if config.API_KEY else 'default'
                                )

                                # è·å–å¹³ä»“å‰çš„5åˆ†é’ŸKçº¿æ•°æ®
                                klines = self.data_manager.get_recent_klines(
                                    inst_id=inst_id,
                                    bar='5m',
                                    limit=80,
                                    end_time=close_time+60*30*1000   # åªè·å–å¹³ä»“æ—¶é—´ä¹‹å‰çš„Kçº¿
                                )
                                if not decisions:
                                    continue

                                # ç”Ÿæˆå¤ç›˜æ€»ç»“ï¼ˆåŒæ­¥è°ƒç”¨ï¼‰
                                logger.info(f"ğŸ“ æ­£åœ¨ä¸ºä»“ä½ç”Ÿæˆå¤ç›˜: {inst_id} {pos_side} open_time={open_time}")
                                review_summary = self.generate_position_review(
                                    position_data=position_data,
                                    decisions=decisions,
                                    klines=klines  # å·²ç»æ˜¯å¹³ä»“å‰çš„Kçº¿
                                )

                                # ä¿å­˜å¤ç›˜æ€»ç»“åˆ°æ•°æ®åº“
                                if review_summary and not review_summary.startswith('å¤ç›˜ç”Ÿæˆå¤±è´¥') and not review_summary.startswith('å¤ç›˜ç”Ÿæˆå¼‚å¸¸'):
                                    success = self.data_manager.update_position_review_summary(
                                        inst_id=inst_id,
                                        pos_side=pos_side,
                                        open_time=open_time,
                                        review_summary=review_summary,
                                        api_key=config.API_KEY if config.API_KEY else 'default'
                                    )
                                    if success:
                                        logger.success(f"âœ… å¤ç›˜æ€»ç»“å·²ä¿å­˜: {inst_id} {pos_side}")
                                        review_count += 1

                            except Exception as e:
                                logger.error(f"âŒ ç”Ÿæˆä»“ä½å¤ç›˜å¤±è´¥: {e}")
                                import traceback
                                logger.debug(traceback.format_exc())
                                continue


            # ä»æ•°æ®åº“åŠ è½½å†å²æ•°æ®åˆ°ç¼“å­˜å¹¶å…³è”å†³ç­–
            historical_positions = self.data_manager.get_recent_closed_positions(
                inst_id=self.inst_id,
                limit=10,
                api_key=config.API_KEY if config.API_KEY else 'default'
            )

            # å…³è”å†³ç­–å†å²
            for pos in historical_positions:
                pos_id = str(pos.get('open_time') ) 
                if pos_id:
                    decisions = self.data_manager.get_decisions_by_pos_id(
                        pos_id,
                        api_key=config.API_KEY if config.API_KEY else 'default'
                    )
                    pos['decisions'] = decisions
                    pos['decision_count'] = len(decisions)
                    pos['open_reason'] = decisions[0]['reason'] if decisions else None
                    pos['adjustments'] = [d for d in decisions if d.get('action') == 'ADJUST_STOP']

            self.cached_historical_positions = historical_positions
            self.cached_performance_stats = self.data_manager.get_performance_stats(
                inst_id=self.inst_id,
                days=30,
                api_key=config.API_KEY if config.API_KEY else 'default'
            )
            self.history_last_update = datetime.now()
            logger.info(
                f"ğŸ“Š åˆå§‹å†å²ä»“ä½: {len(self.cached_historical_positions)}ç¬”å†å², "
                f"30å¤©æ€»äº¤æ˜“: {self.cached_performance_stats.get('total_trades', 0)}ç¬”"
            )
        except Exception as e:
            logger.error(f"âŒ åˆå§‹å†å²ä»“ä½è·å–å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

        # å¯åŠ¨åå°çº¿ç¨‹
        self.position_history_thread = threading.Thread(
            target=self.update_position_history_cache,
            daemon=True,
            name="position-history-updater"
        )
        self.position_history_thread.start()
        logger.info("âœ“ å†å²ä»“ä½æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯30ç§’æ›´æ–°ï¼‰")

    def stop_position_history_thread(self):
        """åœæ­¢å†å²ä»“ä½æ›´æ–°çº¿ç¨‹"""
        if self.position_history_thread and self.position_history_thread.is_alive():
            self.stop_history_thread = True
            self.position_history_thread.join(timeout=5)
            logger.info("âœ“ å†å²ä»“ä½æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def update_funding_rate_cache(self):
        """
        åå°çº¿ç¨‹ï¼šå®šæœŸæ›´æ–°èµ„é‡‘è´¹ç‡ç¼“å­˜
        æ¯20ç§’æ›´æ–°ä¸€æ¬¡
        """
        while not self.stop_funding_rate_thread:
            try:
                result = self.public_api.get_funding_rate(inst_id=self.inst_id)
                if result['code'] == '0' and result.get('data'):
                    self.cached_funding_rate = result['data'][0]
                    self.funding_rate_last_update = datetime.now()

                    # æå–èµ„é‡‘è´¹ç‡ä¿¡æ¯
                    funding_rate = float(self.cached_funding_rate.get('fundingRate', 0))
                    next_funding_time = self.cached_funding_rate.get('nextFundingTime', '')

                    logger.debug(f"âœ“ èµ„é‡‘è´¹ç‡ç¼“å­˜å·²æ›´æ–°: {funding_rate*100:.4f}% (ä¸‹æ¬¡: {next_funding_time})")
                else:
                    logger.warning(f"âš ï¸ èµ„é‡‘è´¹ç‡æ›´æ–°å¤±è´¥: {result.get('msg')}")
            except Exception as e:
                logger.error(f"âŒ èµ„é‡‘è´¹ç‡æ›´æ–°å¼‚å¸¸: {e}")

            time.sleep(20)

    def start_funding_rate_update_thread(self):
        """å¯åŠ¨èµ„é‡‘è´¹ç‡æ›´æ–°åå°çº¿ç¨‹"""
        # ç«‹å³è·å–ä¸€æ¬¡èµ„é‡‘è´¹ç‡
        try:
            result = self.public_api.get_funding_rate(inst_id=self.inst_id)
            if result['code'] == '0' and result.get('data'):
                self.cached_funding_rate = result['data'][0]
                self.funding_rate_last_update = datetime.now()

                funding_rate = float(self.cached_funding_rate.get('fundingRate', 0))
                next_funding_time = self.cached_funding_rate.get('nextFundingTime', '')
                logger.info(f"ğŸ’¸ åˆå§‹èµ„é‡‘è´¹ç‡: {funding_rate*100:.4f}% (ä¸‹æ¬¡: {next_funding_time})")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹èµ„é‡‘è´¹ç‡è·å–å¤±è´¥: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹
        self.funding_rate_update_thread = threading.Thread(
            target=self.update_funding_rate_cache,
            daemon=True,
            name="funding-rate-updater"
        )
        self.funding_rate_update_thread.start()
        logger.info("âœ“ èµ„é‡‘è´¹ç‡æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯20ç§’æ›´æ–°ï¼‰")

    def get_cached_funding_rate(self) -> dict:
        """
        è·å–ç¼“å­˜çš„èµ„é‡‘è´¹ç‡æ•°æ®ï¼ˆæ— é”è®¿é—®ï¼Œæé«˜AIåˆ†ææ•ˆç‡ï¼‰

        Returns:
            ç¼“å­˜çš„èµ„é‡‘è´¹ç‡å­—å…¸
        """
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if self.funding_rate_last_update:
            age_seconds = (datetime.now() - self.funding_rate_last_update).total_seconds()
            if age_seconds > 60:
                logger.warning(f"âš ï¸ èµ„é‡‘è´¹ç‡ç¼“å­˜å·²è¿‡æœŸ ({age_seconds:.0f}ç§’)ï¼Œå¯èƒ½ä¸å‡†ç¡®")
        else:
            logger.warning("âš ï¸ èµ„é‡‘è´¹ç‡ç¼“å­˜æœªåˆå§‹åŒ–")

        return self.cached_funding_rate if self.cached_funding_rate else {}

    def stop_funding_rate_update_thread(self):
        """åœæ­¢èµ„é‡‘è´¹ç‡æ›´æ–°çº¿ç¨‹"""
        if self.funding_rate_update_thread and self.funding_rate_update_thread.is_alive():
            self.stop_funding_rate_thread = True
            self.funding_rate_update_thread.join(timeout=5)
            logger.info("âœ“ èµ„é‡‘è´¹ç‡æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def update_market_data_cache(self):
        """
        åå°çº¿ç¨‹ï¼šå®šæœŸæ›´æ–°å¸‚åœºæ•°æ®ç¼“å­˜ï¼ˆæŒä»“é‡ã€äº¤æ˜“é‡ã€ä¸»åŠ¨ä¹°å–ï¼‰
        æ¯30ç§’æ›´æ–°ä¸€æ¬¡
        """
        while not self.stop_market_data_thread:
            try:
                # 1. è·å–ä¸»åŠ¨ä¹°å–æ•°æ®ï¼ˆ15åˆ†é’Ÿå‘¨æœŸï¼‰
                taker_result = self.trade_api.taker_volume_contract(
                    inst_id=self.inst_id,
                    period='15m',
                    unit=2,  # USDT
                    limit=24  # æœ€è¿‘24ä¸ªæ•°æ®ç‚¹ï¼ˆ6å°æ—¶ï¼‰
                )
                if taker_result.get('code') == '0' and taker_result.get('data'):
                    self.cached_taker_volume = taker_result['data']
                    logger.debug(f"âœ“ ä¸»åŠ¨ä¹°å–æ•°æ®å·²æ›´æ–°: {len(self.cached_taker_volume)}æ¡")
                else:
                    logger.warning(f"âš ï¸ ä¸»åŠ¨ä¹°å–æ•°æ®æ›´æ–°å¤±è´¥: {taker_result.get('msg')}")

                # 2. è·å–æŒä»“é‡å’Œäº¤æ˜“é‡æ•°æ®ï¼ˆ1å°æ—¶å‘¨æœŸï¼‰
                oi_result = self.trade_api.open_interest_volume(
                    inst_id=self.inst_id,
                    period='1H',
                    begin=None,
                    end=None
                )
                if oi_result.get('code') == '0' and oi_result.get('data'):
                    self.cached_open_interest = oi_result['data']
                    logger.debug(f"âœ“ æŒä»“é‡æ•°æ®å·²æ›´æ–°: {len(self.cached_open_interest)}æ¡")
                else:
                    logger.warning(f"âš ï¸ æŒä»“é‡æ•°æ®æ›´æ–°å¤±è´¥: {oi_result.get('msg')}")

                # æ›´æ–°æ—¶é—´æˆ³
                self.market_data_last_update = datetime.now()

            except Exception as e:
                logger.error(f"âŒ å¸‚åœºæ•°æ®æ›´æ–°å¼‚å¸¸: {e}")
                import traceback
                logger.debug(traceback.format_exc())

            time.sleep(30)

    def start_market_data_update_thread(self):
        """å¯åŠ¨å¸‚åœºæ•°æ®æ›´æ–°åå°çº¿ç¨‹"""
        # ç«‹å³è·å–ä¸€æ¬¡æ•°æ®
        try:
            # ä¸»åŠ¨ä¹°å–æ•°æ®
            taker_result = self.trade_api.taker_volume_contract(
                inst_id=self.inst_id,
                period='15m',
                unit=2,
                limit=24
            )
            if taker_result.get('code') == '0' and taker_result.get('data'):
                self.cached_taker_volume = taker_result['data']
                logger.info(f"ğŸ“Š åˆå§‹ä¸»åŠ¨ä¹°å–æ•°æ®: {len(self.cached_taker_volume)}æ¡")

            # æŒä»“é‡æ•°æ®
            oi_result = self.trade_api.open_interest_volume(
                inst_id=self.inst_id,
                period='1H'
            )
            if oi_result.get('code') == '0' and oi_result.get('data'):
                self.cached_open_interest = oi_result['data']
                logger.info(f"ğŸ“Š åˆå§‹æŒä»“é‡æ•°æ®: {len(self.cached_open_interest)}æ¡")

            self.market_data_last_update = datetime.now()

        except Exception as e:
            logger.error(f"âŒ åˆå§‹å¸‚åœºæ•°æ®è·å–å¤±è´¥: {e}")
            import traceback
            logger.debug(traceback.format_exc())

        # å¯åŠ¨åå°çº¿ç¨‹
        self.market_data_update_thread = threading.Thread(
            target=self.update_market_data_cache,
            daemon=True,
            name="market-data-updater"
        )
        self.market_data_update_thread.start()
        logger.info("âœ“ å¸‚åœºæ•°æ®æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨ï¼ˆæ¯30ç§’æ›´æ–°ï¼‰")

    def get_cached_market_data(self) -> tuple:
        """
        è·å–ç¼“å­˜çš„å¸‚åœºæ•°æ®ï¼ˆæ— é”è®¿é—®ï¼Œæé«˜AIåˆ†ææ•ˆç‡ï¼‰

        Returns:
            (cached_taker_volume, cached_open_interest): ä¸»åŠ¨ä¹°å–æ•°æ®å’ŒæŒä»“é‡æ•°æ®
        """
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if self.market_data_last_update:
            age_seconds = (datetime.now() - self.market_data_last_update).total_seconds()
            if age_seconds > 60:
                logger.warning(f"âš ï¸ å¸‚åœºæ•°æ®ç¼“å­˜å·²è¿‡æœŸ ({age_seconds:.0f}ç§’)ï¼Œå¯èƒ½ä¸å‡†ç¡®")
        else:
            logger.warning("âš ï¸ å¸‚åœºæ•°æ®ç¼“å­˜æœªåˆå§‹åŒ–")

        return self.cached_taker_volume, self.cached_open_interest

    def stop_market_data_update_thread(self):
        """åœæ­¢å¸‚åœºæ•°æ®æ›´æ–°çº¿ç¨‹"""
        if self.market_data_update_thread and self.market_data_update_thread.is_alive():
            self.stop_market_data_thread = True
            self.market_data_update_thread.join(timeout=5)
            logger.info("âœ“ å¸‚åœºæ•°æ®æ›´æ–°çº¿ç¨‹å·²åœæ­¢")

    def generate_position_review(self, position_data: dict, decisions: list, klines: list) -> str:
        """
        è°ƒç”¨AIç”Ÿæˆä»“ä½å¤ç›˜æ€»ç»“ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰

        Args:
            position_data: ä»“ä½æ•°æ®å­—å…¸ï¼ŒåŒ…å« inst_id, pos_side, pos, avg_px, mark_px, upl,
                          upl_ratio, fee, open_time, close_time, realized_pnl, holding_duration_seconds
            decisions: AIå†³ç­–å†å²åˆ—è¡¨
            klines: å¹³ä»“å‰çš„5åˆ†é’ŸKçº¿æ•°æ®åˆ—è¡¨

        Returns:
            AIç”Ÿæˆçš„å¤ç›˜æ€»ç»“æ–‡æœ¬
        """
        if not self.ai_client:
            logger.warning("âš ï¸ AIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ç”Ÿæˆå¤ç›˜")
            return "AIå®¢æˆ·ç«¯æœªé…ç½®ï¼Œæ— æ³•ç”Ÿæˆå¤ç›˜æ€»ç»“"

        try:
            # æ ¼å¼åŒ–ä»“ä½ä¿¡æ¯è¡¨æ ¼
            pos_side_display = "Long" if position_data['pos_side'] == 'long' else "Short"
            entry_price = position_data['avg_px']
            exit_price = position_data['mark_px']
            pnl = position_data['realized_pnl']
            pnl_pct = position_data['upl_ratio'] * 100
            fee = position_data.get('fee', 0)
            holding_seconds = position_data.get('holding_duration_seconds', 0)
            holding_hours = holding_seconds / 3600
            close_time_str = datetime.fromtimestamp(position_data['close_time'] / 1000).strftime('%m-%d %H:%M')

            position_table = f"""| # | Side | Size | Entry | Exit | PnL | P&L% | Fee | Hold Time | Close Time |
|---|------|------|-------|------|-----|------|-----|-----------|------------|
| 1 | {pos_side_display} | {position_data['pos']} | {entry_price:.2f} | {exit_price:.2f} | {pnl:.2f} | {pnl_pct:.2f}% | {fee:.2f} | {holding_hours:.1f}h | {close_time_str} |"""

            # æ ¼å¼åŒ–AIå†³ç­–å†å²
            decisions_text = ""
            if decisions:
                decisions_text = "\n**ä»“ä½çš„AIå†³ç­–å†å²:**\n"
                for idx, decision in enumerate(decisions, 1):
                    timestamp_str = decision['timestamp'].strftime('%Y-%m-%d %H:%M:%S') if isinstance(decision['timestamp'], datetime) else str(decision['timestamp'])
                    action = decision['action']
                    confidence = decision.get('confidence', 0)
                    reason = decision.get('reason', '')

                    decisions_text += f"  {idx}. [{timestamp_str}] {action} (ä¿¡å¿ƒ: {confidence}%)\n"

                    # å¦‚æœæ˜¯ ADJUST_STOPï¼Œæ˜¾ç¤ºè°ƒæ•´ä¿¡æ¯
                    if action == 'ADJUST_STOP' and decision.get('adjust_data'):
                        adjust_data = decision['adjust_data']
                        tp_layers = adjust_data.get('take_profit', [])
                        sl_layers = adjust_data.get('stop_loss', [])

                        tp_price = tp_layers[0]['price'] if tp_layers else 0
                        sl_price = sl_layers[0]['price'] if sl_layers else 0

                        decisions_text += f"     è°ƒæ•´: æ­¢ç›ˆ{len(tp_layers)}å±‚, æ­¢æŸ{len(sl_layers)}å±‚, æ­¢ç›ˆä»·: {tp_price:.2f}, æ­¢æŸä»·: {sl_price:.2f}\n"

                    # æ˜¾ç¤ºç†ç”±ï¼ˆå¦‚æœæœ‰ï¼‰
                    if reason and action in ['OPEN_LONG', 'OPEN_SHORT', 'ADJUST_STOP']:
                        # åªæ˜¾ç¤ºå‰200å­—ç¬¦
                        reason_short = reason[:200] + '...' if len(reason) > 200 else reason
                        decisions_text += f"     ç†ç”±: {reason_short}\n"
            else:
                logger.info('ä»“ä½ä¸å­˜åœ¨å†å²å†³ç­–ï¼Œä¸å¤ç›˜')
                return 'å¤ç›˜ç”Ÿæˆå¤±è´¥:ä»“ä½ä¸å­˜åœ¨å†å²å†³ç­–ï¼Œä¸å¤ç›˜'
            # æ ¼å¼åŒ–Kçº¿æ•°æ®
            klines_text = "\n### Kçº¿æ•°æ® (å¹³ä»“å‰æœ€è¿‘15æ ¹5åˆ†é’ŸKçº¿)\n"
            klines_text += "```\n"
            klines_text += "Time    | Open    | High    | Low     | Close   | Volume  | Status\n"
            klines_text += "--------|---------|---------|---------|---------|---------|------\n"

            for kline in klines[-15:]:  # åªå–æœ€å15æ ¹
                timestamp = kline.get('timestamp', 0)
                time_str = datetime.fromtimestamp(timestamp / 1000).strftime('%H:%M')
                open_price = kline.get('open', 0)
                high = kline.get('high', 0)
                low = kline.get('low', 0)
                close = kline.get('close', 0)
                volume = kline.get('volume', 0)
                is_confirmed = kline.get('is_confirmed', True)
                status = 'âœ“' if is_confirmed else 'âŸ³'

                klines_text += f"{time_str} | {open_price:.2f} | {high:.2f} | {low:.2f} | {close:.2f} | {volume:.2f} | {status}\n"

            klines_text += "```\nè‡ªä¸»è¯†åˆ«å½¢æ€"

            # æ„å»ºå®Œæ•´çš„prompt
            prompt = f"""è¿™æ˜¯ä¸Šä¸€æ¬¡äº¤æ˜“çš„ä»“ä½æƒ…å†µå’Œå¸‚åœºè¡Œæƒ…ï¼Œè¯·å¤ç›˜åˆ†æè¯„ä»·ä¸€ä¸‹è¿™ä¸ªä»“ä½çš„æ•´ä¸ªæ“ä½œã€‚

{position_table}

{decisions_text}

{klines_text}


è¯·ç»™å‡ºç®€æ´ä¸“ä¸šçš„å¤ç›˜æ€»ç»“ï¼ˆ300-500å­—ï¼‰ã€‚"""

            # è°ƒç”¨AI
            logger.info(f"ğŸ¤– æ­£åœ¨ç”Ÿæˆä»“ä½å¤ç›˜æ€»ç»“...")
            result = self.ai_client.chat_completion(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ å¯†è´§å¸äº¤æ˜“åˆ†æå¸ˆï¼Œæ“…é•¿å¤ç›˜åˆ†æäº¤æ˜“è®°å½•ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                use_json_mode=False,
                stream=False,
                timeout=60
            )

            if result.get('success'):
                review_summary = result.get('data', '')['choices'][0]['message']['content']
                logger.success(f"âœ“ å¤ç›˜æ€»ç»“ç”ŸæˆæˆåŠŸï¼ˆ{len(review_summary)}å­—ç¬¦ï¼‰")
                return review_summary
            else:
                error_msg = result.get('error', 'unknown')
                logger.warning(f"âš ï¸ AIå¤ç›˜ç”Ÿæˆå¤±è´¥: {error_msg}")
                return f"å¤ç›˜ç”Ÿæˆå¤±è´¥: {error_msg}"

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå¤ç›˜æ€»ç»“å¼‚å¸¸: {e}")
            import traceback
            logger.debug(traceback.format_exc())
            return f"å¤ç›˜ç”Ÿæˆå¼‚å¸¸: {str(e)}"

    def get_cached_historical_data(self) -> tuple:
        """
        è·å–ç¼“å­˜çš„å†å²ä»“ä½æ•°æ®ï¼ˆæ— é”è®¿é—®ï¼Œæé«˜AIåˆ†ææ•ˆç‡ï¼‰

        Returns:
            (cached_historical_positions, cached_performance_stats): å†å²ä»“ä½åˆ—è¡¨å’Œç»Ÿè®¡æ•°æ®
        """
        # å¯¼å…¥datetimeï¼ˆç¡®ä¿åœ¨æ–¹æ³•å†…å¯ç”¨ï¼‰
        from datetime import datetime as dt

        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        if self.history_last_update:
            age_seconds = (dt.now() - self.history_last_update).total_seconds()
            if age_seconds > 60:
                logger.warning(f"âš ï¸ å†å²ä»“ä½ç¼“å­˜å·²è¿‡æœŸ ({age_seconds:.0f}ç§’)ï¼Œå¯èƒ½ä¸å‡†ç¡®")
        else:
            logger.warning("âš ï¸ å†å²ä»“ä½ç¼“å­˜æœªåˆå§‹åŒ–")

        return self.cached_historical_positions, self.cached_performance_stats

    def get_current_positions(self) -> dict:
        """
        è·å–å½“å‰æŒä»“ä¿¡æ¯

        Returns:
            æŒä»“ä¿¡æ¯å­—å…¸
        """
        try:
            result = self.position_api.get_contract_positions(inst_type='SWAP', inst_id=self.inst_id)

            if result['code'] != '0':
                logger.warning(f"è·å–æŒä»“å¤±è´¥: {result.get('msg')}")
                return {'positions': []}

            positions = result.get('data', [])

            # è¿‡æ»¤æ‰æ•°é‡ä¸º0çš„æŒä»“
            active_positions = [p for p in positions if float(p.get('pos', 0)) != 0]

            return {'positions': active_positions}

        except Exception as e:
            logger.error(f"è·å–æŒä»“å¼‚å¸¸: {e}")
            return {'positions': []}

    def check_data_freshness(self, features: dict, timeframe: str) -> tuple[bool, str]:
        """
        æ£€æŸ¥æ•°æ®æ–°é²œåº¦ï¼Œé¿å…åŸºäºæ»åæ•°æ®åšå†³ç­–

        Args:
            features: ç‰¹å¾æ•°æ®
            timeframe: Kçº¿å‘¨æœŸ

        Returns:
            (is_fresh, reason)
        """
        now_ms = int(datetime.now().timestamp() * 1000)
        threshold_ms = self.data_freshness_threshold * 1000

        issues = []

        # 1. æ£€æŸ¥Kçº¿æ•°æ®æ–°é²œåº¦ï¼ˆä½¿ç”¨å®é™…æ›´æ–°æ—¶é—´ï¼Œè€ŒéKçº¿timestampï¼‰
        kline_last_update = self.data_manager.get_kline_last_update(self.inst_id, timeframe)
        if kline_last_update:
            lag_seconds = (now_ms - kline_last_update) / 1000

            if lag_seconds > self.data_freshness_threshold:
                issues.append(f"Kçº¿æ•°æ®æ»å {lag_seconds:.0f} ç§’")
                logger.warning(
                    f"âš ï¸ Kçº¿æ•°æ®æ»å: {lag_seconds:.0f}ç§’ > é˜ˆå€¼ {self.data_freshness_threshold}ç§’ "
                    f"(æœ€åæ›´æ–°: {datetime.fromtimestamp(kline_last_update/1000).strftime('%H:%M:%S')})"
                )
        else:
            issues.append("Kçº¿æ•°æ®æ— æ›´æ–°è®°å½•")
            logger.warning("âš ï¸ Kçº¿æ•°æ®æ— æ›´æ–°è®°å½•ï¼ˆå¯èƒ½æ˜¯é‡‡é›†å™¨æœªå¯åŠ¨æˆ–Redisè¿æ¥å¤±è´¥ï¼‰")

        # 2. æ£€æŸ¥è®¢å•ç°¿æ–°é²œåº¦
        orderbook_raw = features.get('orderbook_raw', {})
        if orderbook_raw and orderbook_raw.get('timestamp'):
            orderbook_ts = orderbook_raw['timestamp']
            lag_seconds = (now_ms - orderbook_ts) / 1000

            if lag_seconds > self.data_freshness_threshold:
                issues.append(f"è®¢å•ç°¿æ•°æ®æ»å {lag_seconds:.0f} ç§’")
                logger.warning(
                    f"âš ï¸ è®¢å•ç°¿æ•°æ®æ»å: {lag_seconds:.0f}ç§’ > é˜ˆå€¼ {self.data_freshness_threshold}ç§’"
                )

        # 3. æ£€æŸ¥æˆäº¤å‹åŠ›æ•°æ®æ–°é²œåº¦
        trades = features.get('trades', {})
        if trades:
            # æ£€æŸ¥æœ€æ–°çš„å‹åŠ›æ•°æ®ï¼ˆ1åˆ†é’Ÿï¼‰
            pressure_1m = self.data_manager.get_latest_pressure(self.inst_id, 60)
            if pressure_1m:
                pressure_ts = pressure_1m['timestamp']
                lag_seconds = (now_ms - pressure_ts) / 1000

                if lag_seconds > self.data_freshness_threshold:
                    issues.append(f"æˆäº¤å‹åŠ›æ•°æ®æ»å {lag_seconds:.0f} ç§’")
                    logger.warning(
                        f"âš ï¸ æˆäº¤å‹åŠ›æ•°æ®æ»å: {lag_seconds:.0f}ç§’ > é˜ˆå€¼ {self.data_freshness_threshold}ç§’"
                    )

        # æ±‡æ€»ç»“æœ
        if issues:
            reason = "æ•°æ®æ»å: " + ", ".join(issues)
            return False, reason

        return True, "æ•°æ®æ–°é²œåº¦æ£€æŸ¥é€šè¿‡"


    async def run_analysis(self) :
        """
        è¿è¡Œä¸€æ¬¡å¢å¼ºåˆ†æï¼ˆåŒå‘¨æœŸç‰ˆæœ¬ï¼š5m + 4Hï¼‰

        Returns:
            åˆ†æç»“æœ
        """
        logger.info("=" * 60)
        logger.info(f" {self.inst_id}")
        logger.info(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("=" * 60)

        # æå–åŒå‘¨æœŸç‰¹å¾
        features = self.feature_engineer.extract_dual_timeframe_features(self.inst_id)

        if not features or not features.get('short_term'):
            logger.error("âŒ ç‰¹å¾æå–å¤±è´¥ï¼Œæ•°æ®ä¸è¶³")
            return {'signal': 'HOLD', 'reason': 'æ•°æ®ä¸è¶³', 'success': False}

        # æ£€æŸ¥æ•°æ®æ–°é²œåº¦ï¼ˆä½¿ç”¨5mæ•°æ®ï¼‰
        is_fresh, freshness_reason = self.check_data_freshness(features, '5m')
        if not is_fresh:
            logger.error(f"âŒ {freshness_reason}")
            logger.warning("âš ï¸ æ•°æ®æ»åè¿‡å¤šï¼Œè·³è¿‡æœ¬æ¬¡åˆ†æä»¥é¿å…é”™è¯¯å†³ç­–")
            return {'signal': 'HOLD', 'reason': freshness_reason, 'success': False}

        logger.info(f"âœ“ {freshness_reason}")

        # æ˜¾ç¤ºç‰¹å¾æ‘˜è¦
        self.display_dual_timeframe_features(features)

        # è·å–å½“å‰æŒä»“ä¿¡æ¯ï¼ˆä»ç¼“å­˜ï¼‰
        position_info = {'positions': self.get_cached_positions()}

        # AIåˆ†æ
        if self.ai_client:
            analysis = await self.ai_analysis(features, position_info)
        else:
            # å›é€€åˆ°è§„åˆ™åˆ†æ
            analysis = self.rule_based_analysis(features)

        # æ˜¾ç¤ºåˆ†æç»“æœ
        
        self.display_analysis(analysis)

        
    def run_conversation(self):
        # å¤„ç†äº¤æ˜“ä¿¡å·
        signal = self.analysis.get('signal')

        if self.auto_execute and signal not in ['HOLD', 'HOLD_LONG', 'HOLD_SHORT']:
            # æ‰§è¡Œäº¤æ˜“ï¼ˆå¼€ä»“/å¹³ä»“/è°ƒæ•´æ­¢ç›ˆæ­¢æŸï¼‰
            #self.execute_trade(analysis)
            try:
                asyncio.run(self.execute_trade())
            except Exception as e:
                logger.error(f'execute_trade æ‰§è¡Œé”™è¯¯:{e}')
        else:
            # HOLDä¿¡å·æˆ–éè‡ªåŠ¨æ‰§è¡Œæ¨¡å¼ï¼šä¿å­˜å¯¹è¯è®°å½•ä½†ä¸äº¤æ˜“
            if signal in ['HOLD', 'HOLD_LONG', 'HOLD_SHORT']:
                logger.info(f"ğŸ’¤ ä¿¡å·ä¸º {signal}ï¼Œä¸æ‰§è¡Œäº¤æ˜“")
            elif not self.auto_execute:
                logger.info(f"ğŸ“‹ ä¿¡å·ä¸º {signal}ï¼Œä½†æœªå¼€å¯è‡ªåŠ¨æ‰§è¡Œ")
            
        return self.analysis
    def display_dual_timeframe_features(self, features: dict):
        """æ˜¾ç¤ºåŒå‘¨æœŸç‰¹å¾æ‘˜è¦"""
        short_term = features.get('short_term', {})
        long_term = features.get('long_term', {})
        kline_raw_5m = features.get('kline_raw_5m', [])
        orderbook_raw = features.get('orderbook_raw', {})

        logger.info("\nğŸ“ˆ çŸ­æœŸæŒ‡æ ‡ï¼ˆ5åˆ†é’Ÿï¼‰:")
        logger.info(f"  ä»·æ ¼: {short_term.get('current_price', 0):.2f} USDT")

        # çŸ­æœŸæŒ‡æ ‡ï¼ˆå–åˆ—è¡¨ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
        ema_20_short = short_term.get('ema_20', [0])
        rsi_7_short = short_term.get('rsi_7', [0])
        rsi_14_short = short_term.get('rsi_14', [0])

        logger.info(f"  EMA20: {ema_20_short[0] if ema_20_short else 0:.2f}")
        logger.info(f"  RSI(7/14): {rsi_7_short[0] if rsi_7_short else 0:.2f} / {rsi_14_short[0] if rsi_14_short else 0:.2f}")

        # MACDæŸ±çŠ¶å›¾ï¼ˆå–åˆ—è¡¨ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
        macd_hist_short = short_term.get('macd_histogram', [0])
        logger.info(f"  MACDæŸ±çŠ¶å›¾: {macd_hist_short[0] if macd_hist_short else 0:.2f}")

        if kline_raw_5m:
            logger.info(f"\nğŸ“Š åŸå§‹Kçº¿: æœ€è¿‘{len(kline_raw_5m)}æ ¹ï¼ˆä¾›AIåˆ†æå½¢æ€ï¼‰")

        logger.info("\nğŸ“Š é•¿æœŸè¶‹åŠ¿ï¼ˆ4å°æ—¶ï¼‰:")

        # é•¿æœŸæŒ‡æ ‡ï¼ˆå–åˆ—è¡¨ç¬¬ä¸€ä¸ªå…ƒç´ ï¼‰
        ema_20_long = long_term.get('ema_20', [0])
        atr_3_long = long_term.get('atr_3', [0])
        volume_ratio = long_term.get('volume_ratio', 1.0)  # è¿™æ˜¯å•ä¸ªå€¼
        macd_hist_long = long_term.get('macd_histogram', [0])
        rsi_14_long = long_term.get('rsi_14', [0])

        logger.info(f"  EMA20: {ema_20_long[0] if ema_20_long else 0:.2f}")
        logger.info(f"  ATR(3): {atr_3_long[0] if atr_3_long else 0:.2f}")
        logger.info(f"  æˆäº¤é‡æ¯”: {volume_ratio:.2f} ({'æ”¾é‡' if volume_ratio > 1.2 else 'ç¼©é‡' if volume_ratio < 0.8 else 'æ­£å¸¸'})")
        logger.info(f"  MACDæŸ±çŠ¶å›¾: {macd_hist_long[0] if macd_hist_long else 0:.2f}")
        logger.info(f"  RSI(14): {rsi_14_long[0] if rsi_14_long else 0:.2f}")

        if orderbook_raw and orderbook_raw.get('bids'):
            logger.info(f"\nğŸ“– è®¢å•ç°¿: {len(orderbook_raw.get('bids', []))}æ¡£ä¹°ç›˜/{len(orderbook_raw.get('asks', []))}æ¡£å–ç›˜")

    def _aggregate_tick_features_realtime(self) -> dict:
        """
        å®æ—¶èšåˆ tick ç‰¹å¾ï¼ˆä» Redis è·å– 60 ç§’æˆäº¤æ•°æ®å¹¶èšåˆï¼‰

        Returns:
            tick_features å­—å…¸ï¼ŒåŒ…å« VWAPã€ä¹°å–é‡å¤±è¡¡ã€ä»·æ ¼æ³¢åŠ¨ç­‰æŒ‡æ ‡
        """
        try:
            import time
            ts = time.time()

            # ä» Redis è·å–è¿‡å» 60 ç§’çš„ tick æ•°æ®
            ticks = self.data_manager.get_recent_trades_from_redis(self.inst_id, seconds=60)

            if not ticks or len(ticks) == 0:
                logger.debug(f"âš ï¸ {self.inst_id}: è¿‡å»60ç§’æ— tickæ•°æ®ï¼Œè¿”å›ç©ºç‰¹å¾")
                return {}

            # æå–ä»·æ ¼å’Œæˆäº¤é‡
            prices = [t['price'] for t in ticks]
            volumes = [t['size'] for t in ticks]

            # 1. è®¡ç®—VWAPï¼ˆæˆäº¤é‡åŠ æƒå¹³å‡ä»·ï¼‰
            total_volume = sum(volumes)
            vwap = sum(p * v for p, v in zip(prices, volumes)) / total_volume if total_volume > 0 else 0

            # 2. è®¡ç®—ä¹°å–é‡å¤±è¡¡
            buy_volume = sum(t['size'] for t in ticks if t['side'] == 'buy')
            sell_volume = sum(t['size'] for t in ticks if t['side'] == 'sell')
            volume_imbalance = buy_volume / sell_volume if sell_volume > 0 else (float('inf') if buy_volume > 0 else 0)

            # 3. è®¡ç®—ä»·æ ¼æ³¢åŠ¨èŒƒå›´
            max_price = max(prices)
            min_price = min(prices)
            price_range = max_price - min_price

            # 4. Tickæ•°é‡
            tick_count = len(ticks)

            # 5. å¤§å•æ¯”ä¾‹ï¼ˆå®šä¹‰å¤§å•ä¸ºæˆäº¤é‡å¤§äºå¹³å‡æˆäº¤é‡çš„2å€ï¼‰
            avg_volume = total_volume / tick_count if tick_count > 0 else 0
            large_trade_threshold = avg_volume * 2
            large_trades = sum(1 for t in ticks if t['size'] > large_trade_threshold)
            large_trade_ratio = large_trades / tick_count if tick_count > 0 else 0

            # ä½¿ç”¨æœ€æ–°tickçš„timestamp
            latest_timestamp = max(t['timestamp'] for t in ticks)

            # æ„å»ºç‰¹å¾å‘é‡
            features = {
                'timestamp': latest_timestamp,
                'vwap': vwap,
                'volume_imbalance': volume_imbalance,
                'price_range': price_range,
                'tick_count': tick_count,
                'large_trade_ratio': large_trade_ratio,
                'buy_volume': buy_volume,
                'sell_volume': sell_volume,
                'total_volume': total_volume,
                'max_price': max_price,
                'min_price': min_price,
                'avg_volume': avg_volume
            }

            logger.debug(
                f"âœ“ å®æ—¶èšåˆTickç‰¹å¾: {self.inst_id} | "
                f"VWAP={vwap:.2f}, ä¹°å–å¤±è¡¡={volume_imbalance:.2f}, "
                f"ä»·æ ¼èŒƒå›´={price_range:.2f}, Tickæ•°={tick_count}, "
                f"å¤§å•æ¯”ä¾‹={large_trade_ratio:.2%}, "
                f"è€—æ—¶={time.time()-ts:.3f}s"
            )

            return features

        except Exception as e:
            logger.error(f"å®æ—¶èšåˆTickç‰¹å¾å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return {}

    async def ai_analysis(self, features: dict, position_info: dict = None) -> dict:
        """AIåˆ†æï¼ˆæµå¼ä¼˜åŒ–ç‰ˆï¼šå½“æ•æ‰åˆ°reasonå­—æ®µæ—¶ç«‹å³å¯åŠ¨å†³ç­–ï¼Œä¸ç­‰reasonå®Œæ•´è¾“å‡ºï¼‰"""
        try:
            # è·å–ç¼“å­˜çš„å†å²ä»“ä½æ•°æ®
            cached_historical_positions, cached_performance_stats = self.get_cached_historical_data()

            # è·å–ç¼“å­˜çš„å¸‚åœºæ•°æ®
            cached_taker_volume, cached_open_interest = self.get_cached_market_data()

            # å®æ—¶è·å–å¹¶èšåˆ tick ç‰¹å¾æ•°æ®ï¼ˆä» 60 ç§’æˆäº¤æ•°æ®ï¼‰
            tick_features = self._aggregate_tick_features_realtime()

            # è®¡ç®—æœºå™¨äººå·²è¿è¡Œæ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰
            bot_runtime_minutes = int((datetime.now() - self.bot_start_time).total_seconds() / 60)

            # ç”Ÿæˆå½“å‰çš„Promptï¼ˆä¼ é€’ä½™é¢ã€åˆçº¦ä¿¡æ¯ã€æ­¢ç›ˆæ­¢æŸè®¢å•ã€å†å²å†³ç­–ã€å†å²ä»“ä½ã€èµ„é‡‘è´¹ç‡ã€å¸‚åœºæ•°æ®ã€tickç‰¹å¾ã€è¿è¡Œæ—¶é•¿ï¼‰
            # è¿”å›(system_prompt, user_prompt)å…ƒç»„
            system_prompt, user_prompt = self.feature_engineer.generate_ai_prompt_with_raw(
                self.inst_id,
                features,
                position_info,
                self.leverage,
                available_balance=self.get_cached_balance(),
                instrument_info=self.instrument_info,
                stop_orders=self.get_cached_stop_orders(),
                ai_decision_history=self.ai_decision_history,  # âœ… ä¼ é€’å†å²å†³ç­–
                historical_positions=cached_historical_positions,  # âœ… ä¼ é€’ç¼“å­˜çš„å†å²ä»“ä½
                performance_stats=cached_performance_stats,  # âœ… ä¼ é€’ç¼“å­˜çš„ç»Ÿè®¡æ•°æ®
                funding_rate=self.get_cached_funding_rate(),  # âœ… ä¼ é€’ç¼“å­˜çš„èµ„é‡‘è´¹ç‡
                taker_volume=cached_taker_volume,  # âœ… ä¼ é€’ä¸»åŠ¨ä¹°å–æ•°æ®
                open_interest=cached_open_interest,  # âœ… ä¼ é€’æŒä»“é‡æ•°æ®
                tick_features=tick_features,  # âœ… ä¼ é€’ tick ç‰¹å¾èšåˆæ•°æ®
                bot_runtime_minutes=bot_runtime_minutes  # âœ… ä¼ é€’è¿è¡Œæ—¶é•¿
            )

            # æ„å»ºmessagesï¼ˆsystem + userï¼Œå†å²å†³ç­–å·²åœ¨user_promptä¸­ï¼‰
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            # æ˜¾ç¤ºå†å²å†³ç­–ä¿¡æ¯
            if self.ai_decision_history:
                logger.info(f"ğŸ“œ ä½¿ç”¨å†å²å†³ç­–ä¸Šä¸‹æ–‡: {len(self.ai_decision_history)} ä¸ªå†³ç­–")

            # è°ƒç”¨AI (æµå¼JSONæ¨¡å¼)
            ai_provider = config.AI_PROVIDER
            logger.info(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ {ai_provider.upper()} AIåˆ†æï¼ˆæµå¼æ¨¡å¼ï¼‰...")
            result = self.ai_client.chat_completion(
                messages=messages,
                temperature=0.5,
                use_json_mode=True,
                stream=True,  # âš¡ å¯ç”¨æµå¼è¾“å‡º
                timeout=None,
                session_id=self.session_id
            )

            # æ£€æŸ¥å“åº”æˆåŠŸæ€§
            if not result.get('success'):
                error_type = result.get('error', 'unknown')
                logger.warning(f"âš ï¸ AIè°ƒç”¨å¤±è´¥: {error_type}")
                return {
                    'signal': 'HOLD',
                    'confidence': 0,
                    'reason': f'AIè°ƒç”¨å¤±è´¥: {error_type}',
                    'success': False,
                    'timeout': True
                }

            # === æµå¼è§£æJSON ===
            streaming_buffer = ""
            early_decision_triggered = False
            early_decision_data = None

            for chunk in result.get('stream', []):
                # æå–å¢é‡å†…å®¹
                try:
                    delta_content = chunk['choices'][0]['delta'].get('content', '')
                    if delta_content:
                        streaming_buffer += delta_content
                        print(delta_content,end='')
                        # å°è¯•æå–æ—©æœŸå†³ç­–ï¼ˆå½“æ£€æµ‹åˆ°reasonå­—æ®µæ—¶ï¼‰
                        if not early_decision_triggered:
                            early_decision = self._try_parse_early_decision(streaming_buffer)
                            if early_decision:
                                early_decision_triggered = True
                                early_decision_data = early_decision
                                self.analysis = self.parse_ai_json_response(early_decision, features)
                                # å¯åŠ¨åå°çº¿ç¨‹ä¿å­˜
                                self.executor_.submit(self.run_conversation)

                except (KeyError, IndexError) as e:
                    logger.debug(f'aiå“åº”æå–é”™è¯¯:{str(e)}')
                    continue

            # æµå¼è¾“å‡ºå®Œæˆï¼Œè§£æå®Œæ•´å“åº”

            try:
                # æ¸…ç†å¯èƒ½çš„markdownæ ‡è®°
                clean_buffer = streaming_buffer.replace('```json', '').replace('```', '').strip()
                complete_response = json.loads(clean_buffer)

                logger.success(f"âœ“ å®Œæ•´JSONè§£ææˆåŠŸ: {complete_response.get('signal')}")

            except json.JSONDecodeError as e:
                logger.error(f"âŒ å®Œæ•´JSONè§£æå¤±è´¥: {e}")
                logger.debug(f"åŸå§‹å“åº”: {streaming_buffer[:500]}")
                # å¦‚æœå®Œæ•´è§£æå¤±è´¥ï¼Œä½†æ—©æœŸå†³ç­–å·²æå–ï¼Œä»å¯ç»§ç»­
                if not early_decision_triggered:
                    return {
                        'signal': 'HOLD',
                        'confidence': 0,
                        'reason': 'JSONè§£æå¤±è´¥',
                        'success': False
                    }
                else:
                    # ä½¿ç”¨æ—©æœŸå†³ç­–æ•°æ®
                    complete_response = early_decision_data
                    complete_response['reason'] = '[æµå¼è§£æå¤±è´¥ï¼Œä½¿ç”¨æ—©æœŸå†³ç­–]'

            # è§£æAIå“åº”ï¼ˆJSONæ ¼å¼ï¼‰
            self.analysis = self.parse_ai_json_response(complete_response, features)

            # ä¿å­˜å®Œæ•´å†³ç­–åˆ°å†å²ï¼ˆåŒ…å«å®Œæ•´reasonï¼‰
            

            # æ·»åŠ å…ƒæ•°æ®
            self.analysis['_user_prompt'] = user_prompt
            self.analysis['_ai_content'] = streaming_buffer
            self.analysis['_features'] = features
            self.analysis['_early_execution'] = early_decision_triggered  # æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†æ—©æœŸæ‰§è¡Œ
            self._save_conversation_async(self.analysis,False)

            return self.analysis

        except Exception as e:
            logger.error(f"AIåˆ†æå¤±è´¥: {e}ï¼Œå›é€€åˆ°è§„åˆ™åˆ†æ")
            import traceback
            logger.debug(f"é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            return {
                'signal': 'HOLD',
                'confidence': 0,
                'reason': 'AIåˆ†æå¤±è´¥',
                'success': False,
                'timeout': True
            }

    def _try_parse_early_decision(self, buffer: str) -> dict:
        """
        å°è¯•ä»ç¼“å†²åŒºä¸­æå–æ—©æœŸå†³ç­–æ•°æ®ï¼ˆä¸åŒ…å«å®Œæ•´reasonï¼‰

        æ£€æµ‹é€»è¾‘ï¼š
        1. å¦‚æœç¼“å†²åŒºä¸­å‡ºç° "reason" å­—æ®µï¼ˆä½†å¯èƒ½æœªå®Œæ•´ï¼‰
        2. æå–é™¤reasonä¹‹å¤–çš„æ‰€æœ‰å¿…è¦å­—æ®µ
        3. æ„å»ºä¸åŒ…å«reasonçš„JSONç”¨äºæ—©æœŸå†³ç­–

        Returns:
            ä¸åŒ…å«å®Œæ•´reasonçš„å†³ç­–JSONï¼Œå¦‚æœæ— æ³•è§£æåˆ™è¿”å›None
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«"reason"å…³é”®å­—
        if '"reason"' not in buffer:
            return None

        try:
            # æ¸…ç†markdownæ ‡è®°
            clean_buffer = buffer.replace('```json', '').replace('```', '').strip()

            # æ‰¾åˆ°"reason"å­—æ®µçš„ä½ç½®
            reason_match = re.search(r'"reason"\s*:\s*"', clean_buffer)
            if not reason_match:
                return None

            reason_start = reason_match.start()

            # æå–"reason"ä¹‹å‰çš„æ‰€æœ‰å†…å®¹
            before_reason = clean_buffer[:reason_start].rstrip(',\n\r\t ')

            # å°è¯•é—­åˆJSONï¼ˆæ·»åŠ }ï¼‰
            if not before_reason.endswith('}'):
                before_reason += '}'

            # å°è¯•è§£æ
            try:
                early_json = json.loads(before_reason)

                # éªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨
                required_fields = ['signal', 'confidence']
                if all(field in early_json for field in required_fields):
                    logger.debug(f"âœ“ æ—©æœŸå†³ç­–JSONè§£ææˆåŠŸ: {early_json.get('signal')}")
                    return early_json
                else:
                    return None

            except json.JSONDecodeError:
                # æ–¹æ³•2ï¼šæ‰‹åŠ¨æå–å…³é”®å­—æ®µï¼ˆregex fallbackï¼‰
                early_json = {}

                # æå–signal
                signal_match = re.search(r'"signal"\s*:\s*"([^"]+)"', before_reason)
                if signal_match:
                    early_json['signal'] = signal_match.group(1)

                # æå–confidence
                conf_match = re.search(r'"confidence"\s*:\s*(\d+)', before_reason)
                if conf_match:
                    early_json['confidence'] = int(conf_match.group(1))

                # æå–sizeï¼ˆå¦‚æœæœ‰ï¼‰
                size_match = re.search(r'"size"\s*:\s*([\d.]+)', before_reason)
                if size_match:
                    early_json['size'] = float(size_match.group(1))

                # æå–stop_loss_rate
                sl_match = re.search(r'"stop_loss_rate"\s*:\s*([\d.]+)', before_reason)
                if sl_match:
                    early_json['stop_loss_rate'] = float(sl_match.group(1))

                # æå–take_profit_rate
                tp_match = re.search(r'"take_profit_rate"\s*:\s*([\d.]+)', before_reason)
                if tp_match:
                    early_json['take_profit_rate'] = float(tp_match.group(1))

                # æå–holding_time
                ht_match = re.search(r'"holding_time"\s*:\s*"([^"]+)"', before_reason)
                if ht_match:
                    early_json['holding_time'] = ht_match.group(1)

                # æå–adjust_typeï¼ˆå¦‚æœæœ‰ï¼‰
                at_match = re.search(r'"adjust_type"\s*:\s*"([^"]+)"', before_reason)
                if at_match:
                    early_json['adjust_type'] = at_match.group(1)

                # æå–new_stop_loss_priceï¼ˆå¦‚æœæœ‰ï¼‰
                nsl_match = re.search(r'"new_stop_loss_price"\s*:\s*([\d.]+)', before_reason)
                if nsl_match:
                    early_json['new_stop_loss_price'] = float(nsl_match.group(1))

                # æå–new_take_profit_priceï¼ˆå¦‚æœæœ‰ï¼‰
                ntp_match = re.search(r'"new_take_profit_price"\s*:\s*([\d.]+)', before_reason)
                if ntp_match:
                    early_json['new_take_profit_price'] = float(ntp_match.group(1))

                # éªŒè¯å¿…éœ€å­—æ®µ
                if 'signal' in early_json and 'confidence' in early_json:
                    logger.debug(f"âœ“ æ—©æœŸå†³ç­–æ‰‹åŠ¨æå–æˆåŠŸ: {early_json.get('signal')}")
                    return early_json
                else:
                    return None

        except Exception as e:
            logger.debug(f"æ—©æœŸå†³ç­–æå–å¤±è´¥: {e}")
            return None

    def _save_complete_decision(self, response: dict):
        """
        ä¿å­˜å®Œæ•´çš„å†³ç­–JSONåˆ°å†å²ï¼ˆåŒ…å«å®Œæ•´reasonï¼‰

        Args:
            response: å®Œæ•´çš„AIå“åº”JSON
        """
        try:
            # ä¿å­˜åˆ°å†å²å†³ç­–ï¼ˆå†…å­˜ï¼‰
            self.ai_decision_history.append({
                'content': json.dumps(response, ensure_ascii=False),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })

            # åªä¿ç•™æœ€è¿‘10æ¡
            if len(self.ai_decision_history) > 10:
                self.ai_decision_history.pop(0)

            # ä¿å­˜åˆ°æ–‡ä»¶
            self._save_decision_history()

            logger.info(f"ğŸ’¾ å®Œæ•´å†³ç­–å·²ä¿å­˜åˆ°æœ¬åœ°ï¼ˆreason: {len(response.get('reason', ''))} å­—ç¬¦ï¼‰")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å®Œæ•´å†³ç­–å¤±è´¥: {e}")

    def parse_ai_json_response(self, response: dict, features: dict) -> dict:
        """è§£æAIçš„JSONå“åº”ï¼ˆç»Ÿä¸€ä½¿ç”¨adjust_dataï¼‰"""
        try:
            # ç›´æ¥ä»JSONæå–å­—æ®µ
            signal = response.get('signal', 'HOLD')

            analysis = {
                'signal': signal,
                'confidence': int(response.get('confidence', 50)),
                'reason': response.get('reason', ''),
                'holding_time': response.get('holding_time', '1å°æ—¶'),
                'risk_warning': response.get('risk_warning', ''),
                'success': True,
                'features': features
            }

            # å¼€ä»“ä¿¡å·éœ€è¦æå–size
            if signal in ['OPEN_LONG', 'OPEN_SHORT']:
                size = response.get('size')
                if size:
                    analysis['size'] = float(size)
                    logger.info(f"âœ“ AIå»ºè®®å¼€ä»“æ•°é‡: {size}å¼ ")
                else:
                    logger.warning("âš ï¸ AIæœªæä¾›sizeå‚æ•°ï¼Œå°†åœ¨æ‰§è¡Œæ—¶è®¡ç®—")

            # æå–adjust_dataï¼ˆå¼€ä»“å’Œè°ƒæ•´æ­¢ç›ˆæ­¢æŸéƒ½éœ€è¦ï¼‰
            if signal in ['OPEN_LONG', 'OPEN_SHORT', 'ADJUST_STOP']:
                adjust_data = response.get('adjust_data')
                if adjust_data:
                    analysis['adjust_data'] = adjust_data

                    tp_count = len(adjust_data.get('take_profit', []))
                    sl_count = len(adjust_data.get('stop_loss', []))
                    logger.info(f"âœ“ AIæä¾›æ­¢ç›ˆæ­¢æŸ: {tp_count}å±‚æ­¢ç›ˆ, {sl_count}å±‚æ­¢æŸ")
                else:
                    if signal in ['OPEN_LONG', 'OPEN_SHORT']:
                        logger.warning("âš ï¸ AIæœªæä¾›adjust_dataï¼Œå¼€ä»“åå°†æ— æ­¢ç›ˆæ­¢æŸä¿æŠ¤")
                    elif signal == 'ADJUST_STOP':
                        logger.error("âŒ ADJUST_STOPä¿¡å·ç¼ºå°‘adjust_dataå­—æ®µ")

            logger.info(f"âœ“ JSONè§£ææˆåŠŸ: {signal} (ç½®ä¿¡åº¦ {analysis['confidence']}%)")
            return analysis

        except Exception as e:
            logger.error(f"JSONå“åº”è§£æå¤±è´¥: {e}")
            return self.rule_based_analysis(features)

    def rule_based_analysis(self, features: dict) -> dict:
        """åŸºäºè§„åˆ™çš„åˆ†æï¼ˆAIä¸å¯ç”¨æ—¶ï¼Œè¿”å›adjust_dataæ ¼å¼ï¼‰"""
        score = features.get('score', {})
        kline = features.get('kline', {})
        trades = features.get('trades', {})

        signal = score.get('signal', 'HOLD')
        total_score = score.get('total_score', 0)

        # è½¬æ¢ä¿¡å·æ ¼å¼
        if signal == 'STRONG_BUY' or signal == 'BUY':
            signal = 'OPEN_LONG'
            confidence = min(85, 50 + abs(total_score))
        elif signal == 'STRONG_SELL' or signal == 'SELL':
            signal = 'OPEN_SHORT'
            confidence = min(85, 50 + abs(total_score))
        else:
            signal = 'HOLD'
            confidence = 50

        analysis = {
            'signal': signal,
            'confidence': confidence,
            'reason': f"è§„åˆ™åˆ†æï¼šç»¼åˆè¯„åˆ†{total_score}åˆ†ï¼Œå‹åŠ›è¶‹åŠ¿{trades.get('pressure_trend', 'N/A')}",
            'holding_time': '1å°æ—¶',
            'success': True,
            'features': features
        }

        # ä¸ºå¼€ä»“ä¿¡å·æ„å»ºadjust_data
        if signal in ['OPEN_LONG', 'OPEN_SHORT']:
            current_price = features.get('short_term', {}).get('current_price', 0)

            if current_price > 0:
                # æ ¹æ®ATRè°ƒæ•´æ­¢æŸæ­¢ç›ˆ
                atr_pct = kline.get('atr_pct', 1.0)
                volatility_factor = min(2.0, max(0.5, atr_pct / 1.0))

                # è®¡ç®—ä»·æ ¼ç™¾åˆ†æ¯”ï¼ˆè´¦æˆ·ç›ˆäºæ¯”ä¾‹ / æ æ† = ä»·æ ¼å˜åŠ¨æ¯”ä¾‹ï¼‰
                base_stop_loss_rate = 0.10  # 10%è´¦æˆ·äºæŸ
                base_take_profit_rate = 0.30  # 30%è´¦æˆ·ç›ˆåˆ©

                stop_loss_rate = max(0.05, min(0.20, base_stop_loss_rate * volatility_factor))
                take_profit_rate = max(0.10, min(0.50, base_take_profit_rate * volatility_factor))

                # è½¬æ¢ä¸ºä»·æ ¼å˜åŠ¨æ¯”ä¾‹
                price_sl_pct = stop_loss_rate / self.leverage
                price_tp_pct = take_profit_rate / self.leverage

                # è®¡ç®—æ­¢ç›ˆæ­¢æŸä»·æ ¼
                if signal == 'OPEN_LONG':
                    stop_loss_price = current_price * (1 - price_sl_pct)
                    take_profit_price = current_price * (1 + price_tp_pct)
                else:  # OPEN_SHORT
                    stop_loss_price = current_price * (1 + price_sl_pct)
                    take_profit_price = current_price * (1 - price_tp_pct)

                # æ³¨æ„ï¼šsize å°†åœ¨ execute_open ä¸­å¡«å……
                analysis['adjust_data'] = {
                    'take_profit': [{'size': None, 'price': round(take_profit_price, 2)}],
                    'stop_loss': [{'size': None, 'price': round(stop_loss_price, 2)}]
                }

                logger.info(f"âœ“ è§„åˆ™åˆ†æç”Ÿæˆå•å±‚æ­¢ç›ˆæ­¢æŸ: TP={take_profit_price:.2f}, SL={stop_loss_price:.2f}")

        return analysis

    def display_analysis(self, analysis: dict):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        signal = analysis.get('signal', 'HOLD')
        confidence = analysis.get('confidence', 0)
        reason = analysis.get('reason', '')
        risk_warning = analysis.get('risk_warning', '')

        # ä¿¡å·å›¾æ ‡
        signal_icons = {
            'OPEN_LONG': 'ğŸŸ¢',
            'OPEN_SHORT': 'ğŸ”´',
            'CLOSE_LONG': 'ğŸŸ¡',
            'CLOSE_SHORT': 'ğŸŸ ',
            'ADJUST_STOP': 'ğŸ”§',
            'HOLD': 'âšª'
        }

        icon = signal_icons.get(signal, 'â“')

        logger.info(f"\n{icon} äº¤æ˜“ä¿¡å·: {signal}")
        logger.info(f"ç½®ä¿¡åº¦: {confidence}%")
        logger.info(f"ç†ç”±: {reason[:200]}...")

        if risk_warning:
            logger.warning(f"âš ï¸ é£é™©æç¤º: {risk_warning}")

        # æ˜¾ç¤ºadjust_data
        adjust_data = analysis.get('adjust_data')
        if adjust_data:
            take_profit = adjust_data.get('take_profit', [])
            stop_loss = adjust_data.get('stop_loss', [])

            logger.info(f"\nğŸ“ æ­¢ç›ˆæ­¢æŸè®¡åˆ’:")

            if take_profit:
                logger.info(f"  æ­¢ç›ˆï¼ˆ{len(take_profit)}å±‚ï¼‰:")
                for i, layer in enumerate(take_profit, 1):
                    size_str = f"{layer['size']:.4f}" if layer.get('size') else "å¾…å®š"
                    logger.info(f"    #{i}: {size_str}å¼  @ {layer['price']:.2f}")

            if stop_loss:
                logger.info(f"  æ­¢æŸï¼ˆ{len(stop_loss)}å±‚ï¼‰:")
                for i, layer in enumerate(stop_loss, 1):
                    size_str = f"{layer['size']:.4f}" if layer.get('size') else "å¾…å®š"
                    logger.info(f"    #{i}: {size_str}å¼  @ {layer['price']:.2f}")

            logger.info(f"  é¢„æœŸæŒä»“: {analysis.get('holding_time', 'N/A')}")

    def validate_adjust_data(self, adjust_data: dict, total_size: float) -> tuple[bool, str]:
        """
        æ ¡éªŒadjust_dataçš„åˆæ³•æ€§

        Returns:
            (is_valid, error_message)
        """
        take_profit = adjust_data.get('take_profit', [])
        stop_loss = adjust_data.get('stop_loss', [])

        # 1. è‡³å°‘æœ‰ä¸€ä¸ª
        if not take_profit and not stop_loss:
            return False, "adjust_dataè‡³å°‘éœ€è¦åŒ…å«take_profitæˆ–stop_loss"

        # 2. æ ¡éªŒsizeæ€»å’Œ
        if take_profit:
            tp_total = sum(layer.get('size', 0) for layer in take_profit)
            if abs(tp_total - total_size) > 0.001:
                return False, f"æ­¢ç›ˆsizeæ€»å’Œ({tp_total:.4f}) â‰  æŒä»“({total_size:.4f})"

        if stop_loss:
            sl_total = sum(layer.get('size', 0) for layer in stop_loss)
            if abs(sl_total - total_size) > 0.001:
                return False, f"æ­¢æŸsizeæ€»å’Œ({sl_total:.4f}) â‰  æŒä»“({total_size:.4f})"

        # 3. æ ¡éªŒå­—æ®µå®Œæ•´æ€§
        for layer in take_profit + stop_loss:
            if 'size' not in layer or 'price' not in layer:
                return False, "æ¯å±‚å¿…é¡»åŒ…å«sizeå’Œpriceå­—æ®µ"
            if layer.get('size', 0) <= 0 or layer.get('price', 0) <= 0:
                return False, "sizeå’Œpriceå¿…é¡»å¤§äº0"

        return True, ""

    def _display_adjust_data(self, adjust_data: dict, current_price: float):
        """æ˜¾ç¤ºadjust_dataæ‘˜è¦"""
        take_profit = adjust_data.get('take_profit', [])
        stop_loss = adjust_data.get('stop_loss', [])

        logger.info("\nğŸ“ æ­¢ç›ˆæ­¢æŸè®¾ç½®:")
        logger.info(f"  å½“å‰ä»·æ ¼: {current_price:.2f}")

        if take_profit:
            logger.info(f"  æ­¢ç›ˆï¼ˆ{len(take_profit)}å±‚ï¼‰:")
            for i, layer in enumerate(take_profit, 1):
                pct = ((layer['price'] - current_price) / current_price) * 100
                logger.info(f"    #{i}: {layer['size']:.4f}å¼  @ {layer['price']:.2f} ({pct:+.2f}%)")

        if stop_loss:
            logger.info(f"  æ­¢æŸï¼ˆ{len(stop_loss)}å±‚ï¼‰:")
            for i, layer in enumerate(stop_loss, 1):
                pct = ((layer['price'] - current_price) / current_price) * 100
                logger.info(f"    #{i}: {layer['size']:.4f}å¼  @ {layer['price']:.2f} ({pct:+.2f}%)")

    async def _apply_adjust_data(self, pos_side: str, adjust_data: dict):
        """
        åº”ç”¨adjust_dataåˆ°æŒ‡å®šä»“ä½

        æµç¨‹ï¼š
        1. æ’¤é”€æ‰€æœ‰ç°æœ‰è®¢å•
        2. åˆ›å»ºæ­¢ç›ˆè®¢å•ï¼ˆé™ä»·æŒ‚å•ï¼‰
        3. åˆ›å»ºæ­¢æŸè®¢å•ï¼ˆç­–ç•¥å§”æ‰˜ï¼‰
        """
        take_profit_layers = adjust_data.get('take_profit', [])
        stop_loss_layers = adjust_data.get('stop_loss', [])

        # 1. æ’¤é”€æ‰€æœ‰ç°æœ‰è®¢å•
        logger.info("  æ’¤é”€ç°æœ‰è®¢å•...")
        await self._cancel_all_position_orders(pos_side)

        # 2. åˆ›å»ºæ­¢ç›ˆè®¢å•ï¼ˆé™ä»·æŒ‚å•ï¼Œmakeræ‰‹ç»­è´¹ï¼‰
        if take_profit_layers:
            logger.info(f"  åˆ›å»º{len(take_profit_layers)}å±‚æ­¢ç›ˆ...")
            await self._create_take_profit_layers(pos_side, take_profit_layers)

        # 3. åˆ›å»ºæ­¢æŸè®¢å•ï¼ˆç­–ç•¥å§”æ‰˜ï¼Œä¿è¯æ‰§è¡Œï¼‰
        if stop_loss_layers:
            logger.info(f"  åˆ›å»º{len(stop_loss_layers)}å±‚æ­¢æŸ...")
            await self._create_stop_loss_layers(pos_side, stop_loss_layers)

        logger.success(
            f"âœ… æ­¢ç›ˆæ­¢æŸå·²è®¾ç½®ï¼š\n"
            f"  æ­¢ç›ˆï¼š{len(take_profit_layers)}å±‚ï¼ˆé™ä»·å•ï¼‰\n"
            f"  æ­¢æŸï¼š{len(stop_loss_layers)}å±‚ï¼ˆç­–ç•¥å•ï¼‰"
        )

    async def _cancel_all_position_orders(self, pos_side: str):
        """æ’¤é”€æŒ‡å®šä»“ä½çš„æ‰€æœ‰è®¢å•ï¼ˆé™ä»·å•+ç­–ç•¥å•ï¼‰"""

        # 1. æ’¤é”€æ™®é€šé™ä»·å•
        try:
            pending_orders = self.trade_api.get_orders_pending(
                inst_id=self.inst_id,
                state='live'
            )

            if pending_orders['code'] == '0':
                for order in pending_orders['data']:
                    if order.get('posSide') == pos_side:
                        self.trade_api.cancel_order(
                            inst_id=self.inst_id,
                            ord_id=order['ordId']
                        )
                        logger.debug(f"  âœ“ æ’¤é”€é™ä»·å•: {order['ordId']}")
        except Exception as e:
            logger.error(f"  âŒ æ’¤é”€é™ä»·å•å¼‚å¸¸: {e}")

        # 2. æ’¤é”€ç­–ç•¥å§”æ‰˜å•
        try:
            algo_orders = self.trade_api.get_algo_order_list(
                ord_type='conditional',
                inst_id=self.inst_id
            )

            if algo_orders['code'] == '0':
                for order in algo_orders['data']:
                    if order.get('posSide') == pos_side:
                        self.trade_api.cancel_algo_order([{
                            'algoId': order['algoId'],
                            'instId': self.inst_id
                        }])
                        logger.debug(f"  âœ“ æ’¤é”€ç­–ç•¥å•: {order['algoId']}")
        except Exception as e:
            logger.error(f"  âŒ æ’¤é”€ç­–ç•¥å•å¼‚å¸¸: {e}")

    async def _create_take_profit_layers(self, pos_side: str, layers: list):
        """åˆ›å»ºåˆ†å±‚æ­¢ç›ˆè®¢å•ï¼ˆé™ä»·æŒ‚å•ï¼‰"""
        close_side = 'sell' if pos_side == 'long' else 'buy'

        for i, layer in enumerate(layers):
            size = layer['size']
            price = layer['price']

            result = self.trade_api.place_order(
                inst_id=self.inst_id,
                td_mode='cross',
                side=close_side,
                ord_type='limit',
                px=str(price),
                sz=str(size),
                posSide=pos_side,
                reduce_only=True
            )

            if result['code'] == '0':
                ord_id = result['data'][0]['ordId']
                logger.debug(f"  âœ“ æ­¢ç›ˆ#{i+1}: {size:.4f}å¼  @ {price:.2f} (ID: {ord_id})")
            else:
                logger.error(f"  âŒ æ­¢ç›ˆ#{i+1}å¤±è´¥: {result.get('msg')}")

    async def _create_stop_loss_layers(self, pos_side: str, layers: list):
        """åˆ›å»ºåˆ†å±‚æ­¢æŸè®¢å•ï¼ˆç­–ç•¥å§”æ‰˜ï¼‰"""
        close_side = 'sell' if pos_side == 'long' else 'buy'

        for i, layer in enumerate(layers):
            size = layer['size']
            trigger_price = layer['price']

            result = self.trade_api.place_algo_order(
                inst_id=self.inst_id,
                td_mode='cross',
                side=close_side,
                ord_type='conditional',
                sz=str(size),
                posSide=pos_side,
                slTriggerPx=str(trigger_price),
                slOrdPx='-1'
            )

            if result['code'] == '0':
                algo_id = result['data'][0]['algoId']
                logger.debug(f"  âœ“ æ­¢æŸ#{i+1}: {size:.4f}å¼  @ {trigger_price:.2f} (ID: {algo_id})")
            else:
                logger.error(f"  âŒ æ­¢æŸ#{i+1}å¤±è´¥: {result.get('msg')}")

    async def execute_trade(self ):
        """æ‰§è¡Œäº¤æ˜“ï¼ˆæ”¯æŒå¼€ä»“/è°ƒæ•´æ­¢ç›ˆæ­¢æŸï¼‰"""
        signal = self.analysis.get('signal')
        confidence = self.analysis.get('confidence', 0)

 

        

        # âš¡ å…ˆæ‰§è¡Œäº¤æ˜“ï¼ˆæé«˜æ•ˆç‡ï¼‰ï¼Œå†ä¿å­˜å¯¹è¯è®°å½•
        current_price = self.analysis['features'].get('short_term', {}).get('current_price', 0)

        # å¤„ç†è°ƒæ•´æ­¢ç›ˆæ­¢æŸä¿¡å·
        if signal == 'ADJUST_STOP':
            await self.execute_adjust_stop(signal, confidence, current_price)
            return

        # å¤„ç†å¼€ä»“ä¿¡å·
        if signal in ['OPEN_LONG', 'OPEN_SHORT']:
            await self.execute_open(signal, confidence, current_price)
            return

    def _save_conversation_async(self, analysis: dict, is_executed: bool = False):
        """
        å¼‚æ­¥ä¿å­˜AIå¯¹è¯è®°å½•ï¼ˆä¸é˜»å¡ä¸»çº¿ç¨‹ï¼‰

        Args:
            analysis: AIåˆ†æç»“æœï¼ˆåŒ…å«ä¸´æ—¶å­˜å‚¨çš„user_promptç­‰ä¿¡æ¯ï¼‰
            is_executed: æ˜¯å¦å·²æ‰§è¡Œäº¤æ˜“
        """
        # æå–ä¸´æ—¶å­˜å‚¨çš„ä¿¡æ¯
        user_prompt = analysis.get('_user_prompt')  # ç°åœ¨åªä¿å­˜useréƒ¨åˆ†
        ai_content = analysis.get('_ai_content')
        features = analysis.get('_features')

        if not user_prompt or not ai_content:
            # è§„åˆ™åˆ†ææ²¡æœ‰è¿™äº›å­—æ®µï¼Œè·³è¿‡ä¿å­˜
            return

        # åœ¨åå°çº¿ç¨‹ä¸­ä¿å­˜ï¼ˆé¿å…é˜»å¡ä¸»çº¿ç¨‹ï¼‰
        def save_task():
            try:
                # å¦‚æœæ˜¯æ›´æ–°æ‰§è¡ŒçŠ¶æ€ï¼ˆis_executed=Trueï¼‰ä¸”å·²æœ‰conversation_idï¼Œåˆ™æ›´æ–°
                if is_executed and self.current_conversation_id:
                    # æ›´æ–°ç°æœ‰è®°å½•çš„æ‰§è¡ŒçŠ¶æ€
                    success = self.data_manager.update_conversation_executed(
                        conversation_id=self.current_conversation_id,
                        is_executed=True,
                        api_key=config.API_KEY if config.API_KEY else 'default'
                    )
                    if success:
                        logger.debug(f"âœ“ å¯¹è¯è®°å½•æ‰§è¡ŒçŠ¶æ€å·²æ›´æ–°: ID={self.current_conversation_id}")
                    else:
                        logger.warning(f"âš ï¸ å¯¹è¯è®°å½•æ‰§è¡ŒçŠ¶æ€æ›´æ–°å¤±è´¥: ID={self.current_conversation_id}")
                    return

                # å¦åˆ™åˆ›å»ºæ–°è®°å½•
                conv_id = self.data_manager.save_conversation(
                    session_id=self.session_id,
                    inst_id=self.inst_id,
                    prompt=user_prompt,  # ä½¿ç”¨user_prompt
                    response=ai_content,
                    analysis=analysis,
                    is_executed=is_executed,
                    api_key=config.API_KEY if config.API_KEY else 'default'
                )

                # è®°å½•ä¼šè¯ID
                self.current_conversation_id = conv_id

                # æ›´æ–°å†…å­˜ç¼“å­˜çš„AIå†³ç­–å†å²ï¼ˆåªä¿ç•™æœ€è¿‘10ä¸ªresponse + æ—¶é—´æˆ³ï¼‰
                # å»æ‰reasonå­—æ®µä»¥å‡å°‘tokenæ¶ˆè€—
                from datetime import datetime
                beijing_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

                # è§£æai_contentï¼Œç§»é™¤reasonå­—æ®µ
                try:
                    import json
                    ai_dict = json.loads(ai_content)
                    # ç§»é™¤reasonå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    ai_dict.pop('reason', None)
                    # ç§»é™¤risk_warningå­—æ®µï¼ˆä¹Ÿæ˜¯å†—é•¿çš„æ–‡æœ¬ï¼‰
                    ai_dict.pop('risk_warning', None)
                    # é‡æ–°åºåˆ—åŒ–ä¸ºJSON
                    ai_content_compact = json.dumps(ai_dict, ensure_ascii=False)
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                    ai_content_compact = ai_content

                self.ai_decision_history.append({
                    "content": ai_content_compact,
                    "timestamp": beijing_time
                })

                # ä¿æŒæœ€å¤š10ä¸ªå†å²å†³ç­–
                if len(self.ai_decision_history) > 10:
                    self.ai_decision_history = self.ai_decision_history[-10:]

                logger.debug(f"âœ“ å¯¹è¯è®°å½•å·²ä¿å­˜: ID={conv_id}, å†å²å†³ç­–æ•°: {len(self.ai_decision_history)}")

                # ğŸ”„ ä¿å­˜å†å²å†³ç­–åˆ°æ–‡ä»¶ï¼ˆåœ¨åŒä¸€ä¸ªåå°çº¿ç¨‹ä¸­æ‰§è¡Œï¼‰
                try:
                    # ç¡®ä¿dataç›®å½•å­˜åœ¨
                    data_dir = os.path.dirname(self.ai_decision_history_file)
                    if not os.path.exists(data_dir):
                        os.makedirs(data_dir, exist_ok=True)

                    # åªä¿ç•™æœ€è¿‘10æ¡
                    history_to_save = self.ai_decision_history[-10:] if len(self.ai_decision_history) > 10 else self.ai_decision_history

                    # å†™å…¥æ–‡ä»¶
                    with open(self.ai_decision_history_file, 'w', encoding='utf-8') as f:
                        json.dump(history_to_save, f, ensure_ascii=False, indent=2)

                    logger.debug(f"âœ“ å†å²å†³ç­–å·²åŒæ­¥åˆ°æ–‡ä»¶: {len(history_to_save)} æ¡")

                except Exception as file_error:
                    logger.error(f"âŒ ä¿å­˜å†å²å†³ç­–æ–‡ä»¶å¤±è´¥: {file_error}")

            except Exception as e:
                logger.error(f"âŒ ä¿å­˜å¯¹è¯è®°å½•å¤±è´¥: {e}")

        # å¯åŠ¨åå°çº¿ç¨‹ä¿å­˜
        save_thread = threading.Thread(target=save_task, daemon=True, name="save-conversation")
        save_thread.start()

    async def execute_adjust_stop(self, signal: str, confidence: int, current_price: float):
        """æ‰§è¡Œè°ƒæ•´æ­¢ç›ˆæ­¢æŸï¼ˆç»Ÿä¸€ä½¿ç”¨adjust_dataï¼‰"""

        adjust_data = self.analysis.get('adjust_data')
        if not adjust_data:
            logger.error("âŒ ADJUST_STOPä¿¡å·ç¼ºå°‘adjust_dataå­—æ®µ")
            return

        logger.info(f"ğŸ”§ æ‰§è¡Œæ­¢ç›ˆæ­¢æŸè°ƒæ•´")

        # è·å–å½“å‰æŒä»“
        positions = self.get_cached_positions()
        if not positions:
            logger.warning("âš ï¸ æ— æŒä»“ï¼Œè·³è¿‡è°ƒæ•´")
            return

        for pos in positions:
            pos_side = pos.get('posSide')
            total_size = abs(float(pos.get('pos', 0)))

            logger.info(f"  è°ƒæ•´{pos_side}ä»“ä½ï¼ˆ{total_size}å¼ ï¼‰")

            # æ ¡éªŒadjust_data
            is_valid, error_msg = self.validate_adjust_data(adjust_data, total_size)
            if not is_valid:
                logger.error(f"âŒ adjust_dataæ ¡éªŒå¤±è´¥: {error_msg}")
                continue

            # æ˜¾ç¤ºè°ƒæ•´è¯¦æƒ…
            self._display_adjust_data(adjust_data, current_price)

            # åº”ç”¨æ–°çš„æ­¢ç›ˆæ­¢æŸ
            await self._apply_adjust_data(pos_side, adjust_data)

            # ä¿å­˜è°ƒæ•´å†³ç­–åˆ°æ•°æ®åº“
            await self._save_adjust_decision_to_db(pos, pos_side)

        # ä¿å­˜å¯¹è¯è®°å½•
        ts = time.time()
        while True:
            if time.time() - ts > 20:
                break
            if self.analysis.get('reason'):
                break

        self.send_feishu_notification(current_price)
        time.sleep(5)
        self._save_conversation_async(self.analysis, is_executed=True)

    async def _adjust_take_profit_layers(
        self, pos_side: str, td_mode: str, current_orders: list, new_layers: list
    ):
        """
        è°ƒæ•´æ­¢ç›ˆå±‚çº§ï¼ˆé™ä»·å•ï¼‰

        Args:
            pos_side: ä»“ä½æ–¹å‘ (long/short)
            td_mode: ä¿è¯é‡‘æ¨¡å¼ (cross/isolated)
            current_orders: å½“å‰æ­¢ç›ˆè®¢å•åˆ—è¡¨
            new_layers: æ–°çš„æ­¢ç›ˆå±‚çº§é…ç½® [{'size': float, 'price': float}, ...]
        """
        try:
            # 1. å–æ¶ˆæ‰€æœ‰æ—§çš„æ­¢ç›ˆé™ä»·å•
            if current_orders:
                logger.info(f"    å–æ¶ˆæ—§çš„æ­¢ç›ˆè®¢å• ({len(current_orders)}å±‚)...")
                cancel_tasks = []
                for order in current_orders:
                    order_id = order.get('order_id')
                    if order_id:
                        cancel_tasks.append(self._cancel_limit_order(order_id))

                # å¹¶å‘å–æ¶ˆ
                if cancel_tasks:
                    await asyncio.gather(*cancel_tasks, return_exceptions=True)
                    logger.info(f"    âœ“ å·²å–æ¶ˆ {len(cancel_tasks)} ä¸ªæ—§æ­¢ç›ˆè®¢å•")

            # 2. ä¸‹æ–°çš„å¤šå±‚æ­¢ç›ˆé™ä»·å•
            logger.info(f"    ä¸‹æ–°çš„æ­¢ç›ˆè®¢å• ({len(new_layers)}å±‚)...")
            close_side = 'sell' if pos_side == 'long' else 'buy'

            place_tasks = []
            for i, layer in enumerate(new_layers, 1):
                size = layer['size']
                price = layer['price']

                # åˆ›å»ºé™ä»·å•ä»»åŠ¡
                task = self._place_limit_order(
                    inst_id=self.inst_id,
                    td_mode=td_mode,
                    side=close_side,
                    pos_side=pos_side,
                    size=str(size),
                    price=str(price)
                )
                place_tasks.append(task)
                logger.debug(f"      Layer {i}: {size:.4f}å¼  @ {price:.2f}")

            # å¹¶å‘ä¸‹å•
            if place_tasks:
                results = await asyncio.gather(*place_tasks, return_exceptions=True)
                success_count = sum(1 for r in results if isinstance(r, dict) and r.get('success'))
                logger.success(f"    âœ… æ­¢ç›ˆè®¢å•ä¸‹å•å®Œæˆ: {success_count}/{len(new_layers)}å±‚æˆåŠŸ")

        except Exception as e:
            logger.error(f"    âŒ è°ƒæ•´æ­¢ç›ˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _adjust_stop_loss_layers(
        self, pos_side: str, td_mode: str, current_orders: list, new_layers: list
    ):
        """
        è°ƒæ•´æ­¢æŸå±‚çº§ï¼ˆæ¡ä»¶å•ï¼‰

        Args:
            pos_side: ä»“ä½æ–¹å‘ (long/short)
            td_mode: ä¿è¯é‡‘æ¨¡å¼ (cross/isolated)
            current_orders: å½“å‰æ­¢æŸè®¢å•åˆ—è¡¨
            new_layers: æ–°çš„æ­¢æŸå±‚çº§é…ç½® [{'size': float, 'price': float}, ...]
        """
        try:
            # 1. å–æ¶ˆæ‰€æœ‰æ—§çš„æ­¢æŸæ¡ä»¶å•
            if current_orders:
                logger.info(f"    å–æ¶ˆæ—§çš„æ­¢æŸè®¢å• ({len(current_orders)}å±‚)...")
                cancel_tasks = []
                for order in current_orders:
                    algo_id = order.get('order_id')
                    if algo_id:
                        cancel_tasks.append(self._cancel_algo_order(algo_id))

                # å¹¶å‘å–æ¶ˆ
                if cancel_tasks:
                    await asyncio.gather(*cancel_tasks, return_exceptions=True)
                    logger.info(f"    âœ“ å·²å–æ¶ˆ {len(cancel_tasks)} ä¸ªæ—§æ­¢æŸè®¢å•")

            # 2. ä¸‹æ–°çš„å¤šå±‚æ­¢æŸæ¡ä»¶å•
            logger.info(f"    ä¸‹æ–°çš„æ­¢æŸè®¢å• ({len(new_layers)}å±‚)...")
            close_side = 'sell' if pos_side == 'long' else 'buy'

            place_tasks = []
            for i, layer in enumerate(new_layers, 1):
                size = layer['size']
                trigger_price = layer['price']

                # åˆ›å»ºæ¡ä»¶å•ä»»åŠ¡
                task = self._place_conditional_order(
                    inst_id=self.inst_id,
                    td_mode=td_mode,
                    side=close_side,
                    pos_side=pos_side,
                    size=str(size),
                    trigger_price=str(trigger_price)
                )
                place_tasks.append(task)
                logger.debug(f"      Layer {i}: {size:.4f}å¼  @ {trigger_price:.2f}")

            # å¹¶å‘ä¸‹å•
            if place_tasks:
                results = await asyncio.gather(*place_tasks, return_exceptions=True)
                success_count = sum(1 for r in results if isinstance(r, dict) and r.get('success'))
                logger.success(f"    âœ… æ­¢æŸè®¢å•ä¸‹å•å®Œæˆ: {success_count}/{len(new_layers)}å±‚æˆåŠŸ")

        except Exception as e:
            logger.error(f"    âŒ è°ƒæ•´æ­¢æŸå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def _place_limit_order(
        self, inst_id: str, td_mode: str, side: str, pos_side: str, size: str, price: str
    ) -> dict:
        """
        ä¸‹é™ä»·å•ï¼ˆæ­¢ç›ˆç”¨ï¼‰

        Returns:
            {'success': bool, 'order_id': str, 'error': str}
        """
        try:
            result = self.trade_api.place_order(
                inst_id=inst_id,
                td_mode=td_mode,
                side=side,
                pos_side=pos_side,
                ord_type='limit',
                sz=size,
                px=price
            )

            if result['code'] == '0':
                order_id = result['data'][0]['ordId']
                return {'success': True, 'order_id': order_id}
            else:
                return {'success': False, 'error': result.get('msg', 'Unknown error')}

        except Exception as e:
            return {'success': False, 'error': str(e)}

    async def _place_conditional_order(
        self, inst_id: str, td_mode: str, side: str, pos_side: str, size: str, trigger_price: str
    ) -> dict:
        """
        ä¸‹æ¡ä»¶å•ï¼ˆæ­¢æŸç”¨ï¼‰

        Returns:
            {'success': bool, 'order_id': str, 'error': str}
        """
        try:
            result = self.trade_api.place_algo_order(
                inst_id=inst_id,
                td_mode=td_mode,
                side=side,
                pos_side=pos_side,
                ord_type='conditional',
                sz=size,
                slTriggerPx=trigger_price,
                slOrdPx='-1'  # å¸‚ä»·æˆäº¤
            )

            if result['code'] == '0':
                algo_id = result['data'][0]['algoId']
                return {'success': True, 'order_id': algo_id}
            else:
                return {'success': False, 'error': result.get('msg', 'Unknown error')}

        except Exception as e:
            return {'success': False, 'error': str(e)}

    async def _cancel_limit_order(self, order_id: str):
        """å–æ¶ˆé™ä»·å•"""
        try:
            result = self.trade_api.cancel_order(
                inst_id=self.inst_id,
                ord_id=order_id
            )
            if result['code'] == '0':
                logger.debug(f"      âœ“ å–æ¶ˆé™ä»·å•æˆåŠŸ: {order_id}")
            else:
                logger.warning(f"      âš ï¸ å–æ¶ˆé™ä»·å•å¤±è´¥: {result.get('msg')}")
        except Exception as e:
            logger.error(f"      âŒ å–æ¶ˆé™ä»·å•å¼‚å¸¸: {e}")

    async def _amend_by_recreate(self, pos: dict, pos_side: str, sl_price: float, tp_price: float):
        """
        é€šè¿‡æ’¤é”€é‡å»ºæ–¹å¼ä¿®æ”¹æ­¢ç›ˆæ­¢æŸï¼ˆå›é€€æ–¹æ¡ˆï¼‰

        Args:
            pos: æŒä»“ä¿¡æ¯
            pos_side: ä»“ä½æ–¹å‘
            sl_price: æ­¢æŸä»·æ ¼
            tp_price: æ­¢ç›ˆä»·æ ¼
        """
        try:
            pos_size = abs(float(pos.get('pos', 0)))
            td_mode = pos.get('mgnMode', 'cross')

            # è·å–å½“å‰è®¢å•
            current_orders = self.cached_stop_orders.get(pos_side, {})
            sl_order = current_orders.get('stop_loss')
            tp_order = current_orders.get('take_profit')

            # å–æ¶ˆæ—§è®¢å•
            if sl_order and sl_order.get('algo_id'):
                await self._cancel_algo_order(sl_order['algo_id'])
            if tp_order and tp_order.get('algo_id') and tp_order.get('algo_id') != sl_order.get('algo_id'):
                await self._cancel_algo_order(tp_order['algo_id'])

            # ä¸‹æ–°çš„OCOè®¢å•
            close_side = 'sell' if pos_side == 'long' else 'buy'

            result = self.trade_api.place_algo_order(
                inst_id=self.inst_id,
                td_mode=td_mode,
                side=close_side,
                ord_type='oco',
                sz=str(pos_size),
                posSide=pos_side,
                slTriggerPx=str(sl_price),
                slOrdPx='-1',  # å¸‚ä»·
                tpTriggerPx=str(tp_price),
                tpOrdPx=str(tp_price),  # é™ä»·
            )

            if result['code'] == '0':
                algo_id = result['data'][0]['algoId']
                logger.success(
                    f"âœ… æ­¢ç›ˆæ­¢æŸå·²è°ƒæ•´ï¼ˆæ’¤é”€é‡å»ºï¼‰ï¼\n"
                    f"  æ–°ç­–ç•¥è®¢å•ID: {algo_id}\n"
                    f"  æ­¢æŸ: {sl_price:.2f}\n"
                    f"  æ­¢ç›ˆ: {tp_price:.2f}"
                )
            else:
                logger.error(f"âŒ æ’¤é”€é‡å»ºå¤±è´¥: {result.get('msg')}")

        except Exception as e:
            logger.error(f"âŒ æ’¤é”€é‡å»ºå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

    async def _create_new_oco_order(self, pos: dict, pos_side: str, sl_price: float, tp_price: float):
        """
        åˆ›å»ºæ–°çš„æ­¢ç›ˆæ­¢æŸOCOè®¢å•

        Args:
            pos: æŒä»“ä¿¡æ¯
            pos_side: ä»“ä½æ–¹å‘
            sl_price: æ­¢æŸä»·æ ¼
            tp_price: æ­¢ç›ˆä»·æ ¼
        """
        try:
            pos_size = abs(float(pos.get('pos', 0)))
            td_mode = pos.get('mgnMode', 'cross')
            close_side = 'sell' if pos_side == 'long' else 'buy'

            logger.info(f"  åˆ›å»ºæ–°çš„OCOè®¢å•: æ­¢æŸ={sl_price:.2f}, æ­¢ç›ˆ={tp_price:.2f}")

            result = self.trade_api.place_algo_order(
                inst_id=self.inst_id,
                td_mode=td_mode,
                side=close_side,
                ord_type='oco',
                sz=str(pos_size),
                posSide=pos_side,
                slTriggerPx=str(sl_price),
                slOrdPx='-1',  # å¸‚ä»·
                tpTriggerPx=str(tp_price),
                tpOrdPx=str(tp_price),  # é™ä»·
            )

            if result['code'] == '0':
                algo_id = result['data'][0]['algoId']
                logger.success(
                    f"âœ… OCOè®¢å•å·²åˆ›å»ºï¼\n"
                    f"  ç­–ç•¥è®¢å•ID: {algo_id}\n"
                    f"  æ­¢æŸ: {sl_price:.2f}\n"
                    f"  æ­¢ç›ˆ: {tp_price:.2f}"
                )
            else:
                logger.error(f"âŒ åˆ›å»ºOCOè®¢å•å¤±è´¥: {result.get('msg')}")

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºOCOè®¢å•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()

    async def _cancel_algo_order(self, algo_id: str):
        """å–æ¶ˆç®—æ³•è®¢å•"""
        try:
            # cancel_algo_order éœ€è¦ä¼ å…¥åˆ—è¡¨æ ¼å¼
            result = self.trade_api.cancel_algo_order([{
                'algoId': algo_id,
                'instId': self.inst_id
            }])
            if result['code'] == '0':
                logger.debug(f"âœ“ å–æ¶ˆè®¢å•æˆåŠŸ: {algo_id}")
            else:
                logger.warning(f"âš ï¸ å–æ¶ˆè®¢å•å¤±è´¥: {result.get('msg')}")
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆè®¢å•å¼‚å¸¸: {e}")

    async def _save_decision_to_db_async(self, signal: str):
        """
        å¼‚æ­¥ä¿å­˜AIå†³ç­–åˆ°æ•°æ®åº“ï¼ˆæŸ¥è¯¢posIdåä¿å­˜ï¼‰

        Args:
            signal: äº¤æ˜“ä¿¡å· (OPEN_LONG/OPEN_SHORT)
        """
        def save_task():
            try:
                # 1. ç­‰å¾…ä»“ä½åˆ›å»ºï¼ˆ0.5ç§’ï¼‰
                time.sleep(0.5)

                # 2. æŸ¥è¯¢posId
                pos_side = 'long' if signal == 'OPEN_LONG' else 'short'
                positions = self.position_api.get_contract_positions(
                    inst_type='SWAP',
                    inst_id=self.inst_id
                )

                pos_id = None
                if positions['code'] == '0':
                    for pos in positions['data']:
                        if pos.get('posSide') == pos_side and float(pos.get('pos', 0)) != 0:
                            pos_id = str(pos.get('cTime'))
                            break

                if not pos_id:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ° {pos_side} ä»“ä½çš„posIdï¼Œè·³è¿‡å†³ç­–ä¿å­˜")
                    return

                # 3. å‡†å¤‡å†³ç­–æ•°æ®ï¼ˆæ–°ç‰ˆï¼šä½¿ç”¨adjust_dataï¼‰
                decision_data = {
                    'timestamp': datetime.now(),
                    'pos_id': pos_id,
                    'inst_id': self.inst_id,
                    'pos_side': pos_side,
                    'action': signal,
                    'size': self.analysis.get('size'),
                    'confidence': self.analysis.get('confidence'),
                    'adjust_data': self.analysis.get('adjust_data'),  # æ–°å­—æ®µ
                    'holding_time': self.analysis.get('holding_time'),
                    'reason': self.analysis.get('reason', '')
                }

                # 4. ä¿å­˜åˆ°æ•°æ®åº“
                record_id = self.data_manager.insert_ai_decision(
                    decision_data,
                    api_key=config.API_KEY if config.API_KEY else 'default'
                )

                if record_id:
                    # æå–adjust_dataä¿¡æ¯ç”¨äºæ—¥å¿—
                    adjust_data = decision_data.get('adjust_data')
                    tp_count = len(adjust_data.get('take_profit', [])) if adjust_data else 0
                    sl_count = len(adjust_data.get('stop_loss', [])) if adjust_data else 0

                    logger.info(
                        f"âœ“ AIå†³ç­–å·²ä¿å­˜åˆ°æ•°æ®åº“: ID={record_id}, posId={pos_id}, "
                        f"æ­¢ç›ˆ{tp_count}å±‚, æ­¢æŸ{sl_count}å±‚"
                    )

            except Exception as e:
                logger.error(f"âŒ ä¿å­˜AIå†³ç­–åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                import traceback
                logger.debug(traceback.format_exc())

        # åœ¨åå°çº¿ç¨‹æ‰§è¡Œ
        thread = threading.Thread(target=save_task, daemon=True, name="save-decision-db")
        thread.start()

    async def _save_adjust_decision_to_db(self, pos: dict, pos_side: str):
        """ä¿å­˜è°ƒæ•´æ­¢ç›ˆæ­¢æŸå†³ç­–åˆ°æ•°æ®åº“ï¼ˆæ–°ç‰ˆï¼šä½¿ç”¨adjust_dataï¼‰"""
        def save_task():
            try:
                pos_id = str(pos.get('cTime'))
                if not pos_id:
                    logger.warning("âš ï¸ posIdä¸å­˜åœ¨ï¼Œè·³è¿‡å†³ç­–ä¿å­˜")
                    return

                # å‡†å¤‡å†³ç­–æ•°æ®
                # ä¿å­˜å¯¹è¯è®°å½•
                ts = time.time()
                while True:
                    if time.time() - ts > 20:
                        break
                    if self.analysis.get('reason'):
                        break
                decision_data = {
                    'timestamp': datetime.now(),
                    'pos_id': pos_id,
                    'inst_id': self.inst_id,
                    'pos_side': pos_side,
                    'action': 'ADJUST_STOP',
                    'confidence': self.analysis.get('confidence'),
                    'adjust_data': self.analysis.get('adjust_data'),  # æ–°å­—æ®µ
                    'reason': self.analysis.get('reason', '')
                }

                # ä¿å­˜åˆ°æ•°æ®åº“
                record_id = self.data_manager.insert_ai_decision(
                    decision_data,
                    api_key=config.API_KEY if config.API_KEY else 'default'
                )

                if record_id:
                    # æå–adjust_dataä¿¡æ¯ç”¨äºæ—¥å¿—
                    adjust_data = decision_data.get('adjust_data')
                    tp_count = len(adjust_data.get('take_profit', [])) if adjust_data else 0
                    sl_count = len(adjust_data.get('stop_loss', [])) if adjust_data else 0

                    logger.info(
                        f"âœ“ è°ƒæ•´å†³ç­–å·²ä¿å­˜: ID={record_id}, posId={pos_id}, "
                        f"æ­¢ç›ˆ{tp_count}å±‚, æ­¢æŸ{sl_count}å±‚"
                    )

            except Exception as e:
                logger.error(f"âŒ ä¿å­˜è°ƒæ•´å†³ç­–å¤±è´¥: {e}")
                import traceback
                logger.debug(traceback.format_exc())

        thread = threading.Thread(target=save_task, daemon=True, name="save-adjust-decision")
        thread.start()

    async def execute_close(self, signal: str, confidence: int, current_price: float, analysis: dict):
        """æ‰§è¡Œå¹³ä»“"""
        # è·å–å½“å‰æŒä»“
        position_info = self.get_current_positions()
        positions = position_info.get('positions', [])

        if not positions:
            logger.warning("âš ï¸ æ— æŒä»“ï¼Œè·³è¿‡å¹³ä»“")
            return

        # ç¡®å®šè¦å¹³ä»“çš„æ–¹å‘
        target_pos_side = 'long' if signal == 'CLOSE_LONG' else 'short'

        # æŸ¥æ‰¾å¯¹åº”æ–¹å‘çš„æŒä»“
        target_position = None
        for pos in positions:
            if pos.get('posSide') == target_pos_side:
                target_position = pos
                break

        if not target_position:
            logger.warning(f"âš ï¸ æ— {target_pos_side}æŒä»“ï¼Œè·³è¿‡å¹³ä»“")
            return

        # è·å–æŒä»“æ•°é‡
        pos_size = abs(float(target_position.get('pos', 0)))
        avg_price = float(target_position.get('avgPx', 0))
        unrealized_pnl = float(target_position.get('upl', 0))

        logger.info(f"ğŸ”„ æ‰§è¡Œå¹³ä»“: {signal}")
        logger.info(f"  æŒä»“æ•°é‡: {pos_size}å¼ ")
        logger.info(f"  å¼€ä»“å‡ä»·: {avg_price:.2f}")
        logger.info(f"  å½“å‰ä»·æ ¼: {current_price:.2f}")
        logger.info(f"  æœªå®ç°ç›ˆäº: {unrealized_pnl:.2f} USDT")

        # å¹³ä»“ï¼šå¤šå¤´å¹³ä»“ç”¨sellï¼Œç©ºå¤´å¹³ä»“ç”¨buy
        side = 'sell' if target_pos_side == 'long' else 'buy'

        # è°ƒç”¨æ™ºèƒ½å¹³ä»“ï¼ˆæ³¨æ„ï¼šsizeå¿…é¡»æ˜¯å­—ç¬¦ä¸²ï¼‰
        result = await self.executor.smart_close_position(
            inst_id=self.inst_id,
            pos_side=target_pos_side,
            size=str(pos_size)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        )

        if result.get('success'):
            logger.success(f"âœ… å¹³ä»“æˆåŠŸï¼ç›ˆäº: {unrealized_pnl:.2f} USDT")
            self.last_trade_time = datetime.now()

            # âš¡ äº¤æ˜“æˆåŠŸåï¼Œåœ¨åå°å¼‚æ­¥ä¿å­˜å¯¹è¯è®°å½•
            self._save_conversation_async(analysis, is_executed=True)

        else:
            logger.error(f"âŒ å¹³ä»“å¤±è´¥: {result.get('error')}")

            # âš¡ äº¤æ˜“å¤±è´¥ï¼Œä¹Ÿä¿å­˜å¯¹è¯è®°å½•
            self._save_conversation_async(analysis, is_executed=False)

    async def execute_open(self, signal: str, confidence: int, current_price: float):
        """æ‰§è¡Œå¼€ä»“ï¼ˆç»Ÿä¸€ä½¿ç”¨adjust_dataï¼‰"""

        # 1. è®¡ç®—å¼€ä»“æ•°é‡
        usdt_balance = self.get_cached_balance()
        logger.info(f"ğŸ’° å¯ç”¨ä½™é¢ï¼ˆç¼“å­˜ï¼‰: {usdt_balance:.2f} USDT")

        # æ£€æŸ¥AIæ˜¯å¦æä¾›äº†size
        ai_size = self.analysis.get('size')

        if ai_size:
            size = ai_size
            logger.info(f"âœ“ ä½¿ç”¨AIå»ºè®®çš„å¼€ä»“æ•°é‡: {size}å¼ ")

            # éªŒè¯sizeçš„åˆæ³•æ€§
            if self.instrument_info:
                min_sz = float(self.instrument_info.get('minSz', 0.01))
                if size < min_sz:
                    logger.warning(f"âš ï¸ AIå»ºè®®çš„size {size} < æœ€å°ä¸‹å•é‡ {min_sz}ï¼Œè°ƒæ•´ä¸º {min_sz}")
                    size = min_sz
        else:
            # AIæœªæä¾›sizeï¼Œä½¿ç”¨ç®€å•è®¡ç®—ï¼š10%å¯ç”¨ä½™é¢
            logger.info(f"AIæœªæä¾›size,ä¸æ‰§è¡Œäº¤æ˜“")
            return

        # 2. æ£€æŸ¥adjust_dataå¹¶è¡¥å……size
        adjust_data = self.analysis.get('adjust_data')

        if adjust_data:
            # è¡¥å……sizeï¼ˆAIå¯èƒ½åªæä¾›äº†priceï¼‰
            for layer in adjust_data.get('take_profit', []):
                if layer.get('size') is None:
                    layer['size'] = size

            for layer in adjust_data.get('stop_loss', []):
                if layer.get('size') is None:
                    layer['size'] = size

            # æ ¡éªŒadjust_data
            is_valid, error_msg = self.validate_adjust_data(adjust_data, size)
            if not is_valid:
                logger.error(f"âŒ adjust_dataæ ¡éªŒå¤±è´¥: {error_msg}")
                return

            logger.info(f"âœ“ adjust_dataæ ¡éªŒé€šè¿‡")
            self._display_adjust_data(adjust_data, current_price)
        else:
            logger.warning("âš ï¸ AIæœªæä¾›adjust_dataï¼Œå¼€ä»“åæ— æ­¢ç›ˆæ­¢æŸä¿æŠ¤")

        # 3. æ‰§è¡Œå¼€ä»“
        side = 'buy' if signal == 'OPEN_LONG' else 'sell'
        logger.info(f"ğŸš€ æ‰§è¡Œå¼€ä»“: {side.upper()} {size}å¼ ")

        # è°ƒç”¨æ™ºèƒ½å¼€ä»“ï¼ˆä¸ä½¿ç”¨executorçš„è‡ªåŠ¨æ­¢ç›ˆæ­¢æŸï¼‰
        result = await self.executor.smart_open_position(
            inst_id=self.inst_id,
            side=side,
            size=str(size),
            leverage=self.leverage,
            auto_stop_orders=False  # ä¸ä½¿ç”¨executorçš„è‡ªåŠ¨æ­¢ç›ˆæ­¢æŸ
        )

        if result.get('success'):
            logger.success(f"âœ… å¼€ä»“æˆåŠŸï¼")
            self.last_trade_time = datetime.now()

            # 4. å¦‚æœæœ‰adjust_dataï¼Œè®¾ç½®æ­¢ç›ˆæ­¢æŸ
            if adjust_data:
                logger.info("ğŸ¯ æ­£åœ¨è®¾ç½®æ­¢ç›ˆæ­¢æŸ...")
                await asyncio.sleep(30)  # ç­‰å¾…ä»“ä½åˆ›å»º

                # è·å–ä»“ä½ä¿¡æ¯
                positions = self.get_cached_positions()
                target_pos = None
                for pos in positions:
                    if pos.get('posSide') == ('long' if side == 'buy' else 'short'):
                        target_pos = pos
                        break

                if target_pos:
                    pos_side = target_pos.get('posSide')
                    await self._apply_adjust_data(pos_side, adjust_data)
                else:
                    logger.error("âŒ æœªæ‰¾åˆ°æ–°å¼€ä»“ä½ï¼Œæ— æ³•è®¾ç½®æ­¢ç›ˆæ­¢æŸ")

            # 5. ä¿å­˜å†³ç­–åˆ°æ•°æ®åº“
            await self._save_decision_to_db_async(signal)

            # 6. ä¿å­˜å¯¹è¯è®°å½•
            ts = time.time()
            while True:
                if time.time() - ts > 15:
                    self._save_conversation_async(self.analysis, is_executed=True)
                    self.send_feishu_notification(current_price)
                    break
                if self.analysis.get('reason'):
                    self._save_conversation_async(self.analysis, is_executed=True)
                    self.send_feishu_notification(current_price)
                    break

        else:
            logger.error(f"âŒ å¼€ä»“å¤±è´¥: {result.get('error')}")

            # ä¿å­˜å¯¹è¯è®°å½•
            ts = time.time()
            while True:
                if time.time() - ts > 15:
                    self._save_conversation_async(self.analysis, is_executed=False)
                    self.send_feishu_notification(current_price)
                    break
                if self.analysis.get('reason'):
                    self._save_conversation_async(self.analysis, is_executed=False)
                    self.send_feishu_notification(current_price)
                    break

    async def run_continuous(self, interval_seconds: float = 60):
        """æŒç»­ç›‘æ§æ¨¡å¼ï¼ˆåŒå‘¨æœŸç‰ˆæœ¬ï¼‰"""
        logger.info(f"  æ£€æŸ¥é—´éš”: {interval_seconds}ç§’")
        

        # âš¡ å¯åŠ¨æ‰€æœ‰åå°çº¿ç¨‹
        self.start_balance_update_thread()
        self.start_position_update_thread()
        self.start_stop_order_update_thread()
        self.start_position_history_thread()  # âœ… å¯åŠ¨å†å²ä»“ä½æ›´æ–°çº¿ç¨‹
        self.start_funding_rate_update_thread()  # âœ… å¯åŠ¨èµ„é‡‘è´¹ç‡æ›´æ–°çº¿ç¨‹
        self.start_market_data_update_thread()  # âœ… å¯åŠ¨å¸‚åœºæ•°æ®æ›´æ–°çº¿ç¨‹



        iteration = 0
        await asyncio.sleep(5)

        try:
            while True:
                iteration += 1
                logger.info(f"\n{'='*60}")
                logger.info(f"ç¬¬ {iteration} æ¬¡æ‰«æ")
                logger.info(f"{'='*60}")

                await self.run_analysis()

                logger.info(f"\nâ³ ç­‰å¾… {interval_seconds} ç§’...")
                await asyncio.sleep(interval_seconds)

        except KeyboardInterrupt:
            logger.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            logger.error(f"âŒ ç›‘æ§é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # åœæ­¢æ‰€æœ‰åå°çº¿ç¨‹
            self.stop_balance_update_thread()
            self.stop_position_update_thread()
            self.stop_stop_order_update_thread()
            self.stop_position_history_thread()  # âœ… åœæ­¢å†å²ä»“ä½æ›´æ–°çº¿ç¨‹
            self.stop_funding_rate_update_thread()  # âœ… åœæ­¢èµ„é‡‘è´¹ç‡æ›´æ–°çº¿ç¨‹
            self.stop_market_data_update_thread()  # âœ… åœæ­¢å¸‚åœºæ•°æ®æ›´æ–°çº¿ç¨‹

            # åœæ­¢å®æ—¶é‡‡é›†
            if self.realtime_collector:
                self.realtime_collector.stop()
                if self.collector_task:
                    self.collector_task.cancel()
                logger.info("âœ“ å®æ—¶æ•°æ®é‡‡é›†å·²åœæ­¢")

            # å…³é—­è®¢å•ç›‘æ§å™¨
            if hasattr(self.executor, 'order_monitor'):
                self.executor.order_monitor.shutdown()
                logger.info("âœ“ è®¢å•ç›‘æ§å™¨å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='BTC-USDT-SWAP å¢å¼ºç‰ˆçŸ­çº¿äº¤æ˜“æœºå™¨äººï¼ˆåŒå‘¨æœŸç‰ˆæœ¬ï¼š5m+4Hï¼‰')

    parser.add_argument('--once', action='store_true', help='è¿è¡Œä¸€æ¬¡åˆ†æåé€€å‡º')
    parser.add_argument('--continuous', action='store_true', help='æŒç»­ç›‘æ§æ¨¡å¼')
    parser.add_argument('--interval', type=float, default=60, help='æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰')
    parser.add_argument('--auto-execute', action='store_true', help='è‡ªåŠ¨æ‰§è¡Œäº¤æ˜“')
    #parser.add_argument('--no-realtime', action='store_true', help='ç¦ç”¨å®æ—¶æ•°æ®é‡‡é›†')

    args = parser.parse_args()

    # åˆ›å»ºæœºå™¨äºº
    bot = BTCEnhancedBotRaw(
        auto_execute=args.auto_execute,
    )

    # å•æ¬¡åˆ†æ
    if args.once:
        await bot.run_analysis()
        return

    # æŒç»­ç›‘æ§
    if args.continuous:
        await bot.run_continuous(args.interval)
        return

    # é»˜è®¤ï¼šæ˜¾ç¤ºå¸®åŠ©
    parser.print_help()
    logger.info("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š")
    logger.info("  1. å•æ¬¡åˆ†æ: python examples/enhanced_trading.py --once")
    logger.info("  2. æŒç»­ç›‘æ§: python examples/enhanced_trading.py --continuous --interval 60")
    logger.info("  3. è‡ªåŠ¨äº¤æ˜“: python examples/enhanced_trading.py --continuous --auto-execute")


if __name__ == '__main__':
    PID_FILE = os.path.join(project_root, "data", "bot.pid")
    with open(PID_FILE, 'w') as f:
        f.write(str(os.getpid()))
    # é…ç½®æ—¥å¿—è¾“å‡º 
    logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.add(
        sys.stderr,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>",
        level="INFO"
    )

    # æ·»åŠ æ–‡ä»¶æ—¥å¿—
    logger.add(
        "logs/trading_bot_{time:YYYY-MM-DD}.log",
        rotation="00:00",
        retention="7 days",
        level="INFO"
    )
    logger.info(f"Bot PID: {os.getpid()}")

    asyncio.run(main())
